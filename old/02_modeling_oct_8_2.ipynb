{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### **0. Setup and Installations**"
      ],
      "metadata": {
        "id": "o-mS-h3Ik30p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY70zhGiktnZ",
        "outputId": "a8390171-a431-4c1c-b002-b5fae592d711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting Hugging Face login...\n",
            "Hugging Face login successful.\n"
          ]
        }
      ],
      "source": [
        "# --- Hugging Face Authentication (using Colab Secrets) ---\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "print(\"Attempting Hugging Face login...\")\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"Hugging Face login successful.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not log in. Please ensure 'HF_TOKEN' is a valid secret. Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not mount Google Drive. Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJLJ4mbMQOG0",
        "outputId": "888e99e0-b5d8-4431-981f-8ad5942cc72d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Install Dependencies ---\n",
        "!pip install pandas\n",
        "!pip install pyarrow\n",
        "!pip install sentence-transformers\n",
        "!pip install scikit-learn\n",
        "!pip install torch\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ2v1yVxk79e",
        "outputId": "52b79696-3398-4eb9-894e-0251df3fa25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. Configuration and Helper Functions**\n",
        "\n",
        "This section contains all hyperparameters and the new functions for data loading and splitting."
      ],
      "metadata": {
        "id": "1Kecda6zlEbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display, clear_output\n",
        "import json"
      ],
      "metadata": {
        "id": "7M2d2yhqlafF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Seeding function for reproducibility ---\n",
        "def set_seed(seed: int):\n",
        "    \"\"\"Sets the seed for all relevant RNGs to ensure reproducibility.\"\"\"\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed) # for multi-GPU\n",
        "        # These are crucial for reproducibility on GPU\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    print(f\"All random seeds set to {seed}.\")\n",
        "\n",
        "class Config:\n",
        "    # --- Data and Environment ---\n",
        "    CITY: str = \"nyc\"\n",
        "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    DRIVE_SAVE_PATH: str = \"/content/drive/MyDrive/Colab_Notebooks/Airbnb_Project/\"\n",
        "\n",
        "    # --- Data Pre-processing ---\n",
        "    VAL_SIZE: float = 0.2\n",
        "\n",
        "    # --- Reproducibility ---\n",
        "    SEED: int = 42 # Master seed for the entire experiment\n",
        "\n",
        "    # --- Model Training ---\n",
        "    BATCH_SIZE: int = 1024\n",
        "    LEARNING_RATE: float = 1e-3\n",
        "    N_EPOCHS: int = 20\n",
        "\n",
        "    # --- Logging ---\n",
        "    LOG_EVERY_N_STEPS: int = 10 # Log and validate every N training steps"
      ],
      "metadata": {
        "id": "9GzwsZ61lGJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Data Loading and Splitting**\n",
        "\n",
        "This function handles loading, outlier removal, and the 3-way stratified split."
      ],
      "metadata": {
        "id": "zpZgvwABtJbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_split_data(config: Config):\n",
        "    \"\"\"\n",
        "    Loads data, removes price outliers, and performs a 3-way stratified split.\n",
        "    \"\"\"\n",
        "    dataset_filename = f\"{config.CITY}_final_modeling_dataset.parquet\"\n",
        "    dataset_path = f\"./{dataset_filename}\" # Assumes file in root Colab runtime\n",
        "\n",
        "    if not os.path.exists(dataset_path):\n",
        "        raise FileNotFoundError(f\"'{dataset_filename}' not found. Please upload the file to the Colab Runtime.\")\n",
        "\n",
        "    print(f\"Loading dataset from: {dataset_path}\")\n",
        "    df = pd.read_parquet(dataset_path)\n",
        "\n",
        "    # Remove price outliers (top/bottom 1%)\n",
        "    price_q01 = df['target_price'].quantile(0.01)\n",
        "    price_q99 = df['target_price'].quantile(0.99)\n",
        "    df = df[(df['target_price'] >= price_q01) & (df['target_price'] <= price_q99)].copy()\n",
        "    print(f\"Removed price outliers. New size: {len(df):,} records.\")\n",
        "\n",
        "    # Create bins for stratifying continuous price\n",
        "    df['price_bin'] = pd.cut(df['target_price'], bins=10, labels=False)\n",
        "\n",
        "    # Create a combined key for 3-way stratification\n",
        "    stratify_key = (\n",
        "        df['neighbourhood_cleansed'].astype(str) + '_' +\n",
        "        df['month'].astype(str) + '_' +\n",
        "        df['price_bin'].astype(str)\n",
        "    )\n",
        "\n",
        "    # Handle small strata (<2 members)\n",
        "    strata_counts = stratify_key.value_counts()\n",
        "    valid_strata = strata_counts[strata_counts >= 2].index\n",
        "    df_filtered = df[stratify_key.isin(valid_strata)].copy()\n",
        "    print(f\"Removed small strata. New size: {len(df_filtered):,} records.\")\n",
        "\n",
        "    # Perform stratified split\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        df_filtered.index,\n",
        "        test_size=config.VAL_SIZE,\n",
        "        random_state=config.SEED,\n",
        "        stratify=stratify_key[df_filtered.index]\n",
        "    )\n",
        "\n",
        "    train_df = df_filtered.loc[train_indices].copy().reset_index(drop=True)\n",
        "    val_df = df_filtered.loc[val_indices].copy().reset_index(drop=True)\n",
        "\n",
        "    print(f\"Split complete. Training: {len(train_df):,}, Validation: {len(val_df):,}\")\n",
        "\n",
        "    print(\"\\n--- Sample Record from Training Data ---\")\n",
        "    # Pretty-print the first record by transposing it\n",
        "    display(train_df.head(1).T)\n",
        "\n",
        "    return train_df, val_df"
      ],
      "metadata": {
        "id": "kszCgSb1lPWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Feature Processor**\n",
        "\n",
        "This class encapsulates the feature engineering logic as defined in `EMBEDDINGS.md`. It learns transformations (like vocabularies and scaling parameters) from the training data via the `.fit()` method. The `.transform()` method then consistently applies these learned transformations to any dataset, preventing data leakage. This is a crucial step for creating model-ready tensors from raw dataframes."
      ],
      "metadata": {
        "id": "IOVmfA44lizn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureProcessor:\n",
        "    def __init__(self, embedding_dim_geo: int = 32):\n",
        "        self.vocabs, self.scalers = {}, {}\n",
        "        self.embedding_dim_geo = embedding_dim_geo\n",
        "        self.categorical_cols = [\n",
        "            \"neighbourhood_cleansed\",\n",
        "            \"property_type\",\n",
        "            \"room_type\",\n",
        "            \"bathrooms_type\",\n",
        "            \"bedrooms\",\n",
        "            \"beds\",\n",
        "            \"bathrooms_numeric\"\n",
        "            ]\n",
        "        self.numerical_cols = [\n",
        "            \"accommodates\",\n",
        "            \"review_scores_rating\",\n",
        "            \"review_scores_cleanliness\",\n",
        "            \"review_scores_checkin\",\n",
        "            \"review_scores_communication\",\n",
        "            \"review_scores_location\",\n",
        "            \"review_scores_value\",\n",
        "            \"host_response_rate\",\n",
        "            \"host_acceptance_rate\"\n",
        "            ]\n",
        "        self.log_transform_cols = [\"number_of_reviews_ltm\"]\n",
        "        self.boolean_cols = [\n",
        "            \"host_is_superhost\",\n",
        "            \"host_identity_verified\",\n",
        "            \"instant_bookable\"\n",
        "            ]\n",
        "\n",
        "    def _create_positional_encoding(self, value, max_val):\n",
        "        d = self.embedding_dim_geo\n",
        "        if d % 2 != 0: raise ValueError(\"embedding_dim_geo must be even.\")\n",
        "        pe = np.zeros(d)\n",
        "        position = (value / max_val) * 10000\n",
        "        div_term = np.exp(np.arange(0, d, 2) * -(np.log(10000.0) / d))\n",
        "        pe[0::2] = np.sin(position * div_term)\n",
        "        pe[1::2] = np.cos(position * div_term)\n",
        "        return pe\n",
        "\n",
        "    def fit(self, df: pd.DataFrame):\n",
        "        for col in self.categorical_cols:\n",
        "            valid_uniques = df[col].dropna().unique().tolist()\n",
        "            self.vocabs[col] = {val: i for i, val in enumerate([\"<UNK>\"] + sorted(valid_uniques))}\n",
        "        for col in self.numerical_cols + self.log_transform_cols:\n",
        "            vals = np.log1p(df[col]) if col in self.log_transform_cols else df[col]\n",
        "            self.scalers[col] = {'mean': vals.mean(), 'std': vals.std()}\n",
        "\n",
        "    def transform(self, df: pd.DataFrame) -> dict:\n",
        "        df = df.copy()\n",
        "        half_dim = self.embedding_dim_geo // 2\n",
        "        lat_enc = df['latitude'].apply(lambda x: self._create_positional_encoding(x, 90)[:half_dim])\n",
        "        lon_enc = df['longitude'].apply(lambda x: self._create_positional_encoding(x, 180)[:half_dim])\n",
        "\n",
        "        # --- Axis 1: Location ---\n",
        "        half_dim = self.embedding_dim_geo // 2\n",
        "        lat_enc = df['latitude'].apply(lambda x: self._create_positional_encoding(x, 90)[:half_dim])\n",
        "        lon_enc = df['longitude'].apply(lambda x: self._create_positional_encoding(x, 180)[:half_dim])\n",
        "        geo_position = np.hstack([np.stack(lat_enc), np.stack(lon_enc)])\n",
        "        neighbourhood = df[\"neighbourhood_cleansed\"].apply(lambda x: self.vocabs[\"neighbourhood_cleansed\"].get(x, 0)).values\n",
        "        location_features = {\"geo_position\": geo_position, \"neighbourhood\": neighbourhood}\n",
        "\n",
        "        # --- Axis 2: Size & Capacity ---\n",
        "        size_features = {}\n",
        "        for col in [\"property_type\", \"room_type\", \"bathrooms_type\", \"bedrooms\", \"beds\", \"bathrooms_numeric\"]:\n",
        "            size_features[col] = df[col].apply(lambda x: self.vocabs[col].get(x, 0) if pd.notna(x) else 0).values\n",
        "        size_features[\"accommodates\"] = ((df[\"accommodates\"] - self.scalers[\"accommodates\"][\"mean\"]) / self.scalers[\"accommodates\"][\"std\"]).values\n",
        "\n",
        "        # --- Axis 3: Quality & Reputation ---\n",
        "        quality_features = {}\n",
        "        for col in self.numerical_cols:\n",
        "            if col != \"accommodates\":\n",
        "                quality_features[col] = ((df[col] - self.scalers[col][\"mean\"]) / self.scalers[col][\"std\"]).values\n",
        "        quality_features[\"number_of_reviews_ltm\"] = ((np.log1p(df[\"number_of_reviews_ltm\"]) - self.scalers[\"number_of_reviews_ltm\"][\"mean\"]) / self.scalers[\"number_of_reviews_ltm\"][\"std\"]).values\n",
        "        for col in self.boolean_cols:\n",
        "            quality_features[col] = df[col].astype(float).values\n",
        "\n",
        "        # --- Axis 5: Seasonality ---\n",
        "        month_sin = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
        "        month_cos = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
        "        seasonality_features = {\"cyclical\": np.vstack([month_sin, month_cos]).T}\n",
        "\n",
        "        return {\n",
        "            \"location\": location_features,\n",
        "            \"size_capacity\": size_features,\n",
        "            \"quality\": quality_features,\n",
        "            \"amenities\": {\"text\": df[\"amenities\"].tolist()},\n",
        "            \"seasonality\": seasonality_features,\n",
        "            \"target_log_price\": np.log1p(df[\"target_price\"].values),\n",
        "            \"sample_weight\": df[\"estimated_occupancy_rate\"].values\n",
        "        }"
      ],
      "metadata": {
        "id": "v2tlR__3lsm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. AirbnbDataset Class**\n",
        "\n",
        "The PyTorch `Dataset` class, which defines how to retrieve a single item from our processed feature dictionary."
      ],
      "metadata": {
        "id": "oifKuGPcnah9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class AirbnbPriceDataset(Dataset):\n",
        "#     def __init__(self, features: dict):\n",
        "#         self.features = features\n",
        "#         self.n_samples = len(features['sample_weight'])\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.n_samples\n",
        "\n",
        "#     def __getitem__(self, index: int) -> dict:\n",
        "#         item = {}\n",
        "#         # Location\n",
        "#         item['loc_geo_position'] = torch.tensor(self.features['location']['geo_position'][index], dtype=torch.float32)\n",
        "#         item['loc_neighbourhood'] = torch.tensor(self.features['location']['neighbourhood'][index], dtype=torch.long)\n",
        "\n",
        "#         # Size & Capacity\n",
        "#         for k, v in self.features['size_capacity'].items():\n",
        "#             dtype = torch.float32 if k == 'accommodates' else torch.long\n",
        "#             item[f'size_{k}'] = torch.tensor(v[index], dtype=dtype)\n",
        "\n",
        "#         # Quality\n",
        "#         for k, v in self.features['quality'].items():\n",
        "#             item[f'qual_{k}'] = torch.tensor(v[index], dtype=torch.float32)\n",
        "\n",
        "#         # Amenities & Seasonality\n",
        "#         item['amenities_text'] = self.features['amenities']['text'][index]\n",
        "#         item['season_cyclical'] = torch.tensor(self.features['seasonality']['cyclical'][index], dtype=torch.float32)\n",
        "\n",
        "#         # Target & Weight\n",
        "#         item['target'] = torch.tensor(self.features['target_log_price'][index], dtype=torch.float32)\n",
        "#         item['sample_weight'] = torch.tensor(self.features['sample_weight'][index], dtype=torch.float32)\n",
        "\n",
        "#         return item\n",
        "\n",
        "# (This cell replaces your existing AirbnbPriceDataset class definition)\n",
        "\n",
        "# (This cell replaces the AirbnbPriceDataset class)\n",
        "\n",
        "class AirbnbPriceDataset(Dataset):\n",
        "    def __init__(self, features: dict):\n",
        "        self.features = features\n",
        "        self.n_samples = len(features['sample_weight'])\n",
        "\n",
        "    def __len__(self): return self.n_samples\n",
        "\n",
        "    def __getitem__(self, index: int) -> dict:\n",
        "        # Reverting to torch.tensor() calls as input is now CPU numpy/tensors\n",
        "        item = {}\n",
        "        item['loc_geo_position'] = torch.tensor(self.features['location']['geo_position'][index], dtype=torch.float32)\n",
        "        item['loc_neighbourhood'] = torch.tensor(self.features['location']['neighbourhood'][index], dtype=torch.long)\n",
        "        for k, v in self.features['size_capacity'].items():\n",
        "            dtype = torch.float32 if k == 'accommodates' else torch.long\n",
        "            item[f'size_{k}'] = torch.tensor(v[index], dtype=dtype)\n",
        "        for k, v in self.features['quality'].items():\n",
        "            item[f'qual_{k}'] = torch.tensor(v[index], dtype=torch.float32)\n",
        "        item['amenities_text'] = self.features['amenities']['text'][index]\n",
        "        item['season_cyclical'] = torch.tensor(self.features['seasonality']['cyclical'][index], dtype=torch.float32)\n",
        "        item['target'] = torch.tensor(self.features['target_log_price'][index], dtype=torch.float32)\n",
        "        item['sample_weight'] = torch.tensor(self.features['sample_weight'][index], dtype=torch.float32)\n",
        "        return item"
      ],
      "metadata": {
        "id": "HekaBx8inlWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Dataloader Creation**\n",
        "\n",
        "A function to create the `DataLoader` instances, including the custom collate function for batch tokenization."
      ],
      "metadata": {
        "id": "rti3lqEqvXGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (This cell replaces the 'preprocess_and_tensorize' and 'create_dataloaders' functions)\n",
        "\n",
        "def preprocess_and_tensorize_CPU(processor, df):\n",
        "    \"\"\"\n",
        "    Applies the feature processor and converts data to CPU tensors.\n",
        "    \"\"\"\n",
        "    features_cpu = processor.transform(df)\n",
        "\n",
        "    # Create a new dictionary for CPU tensors\n",
        "    features_tensor = {}\n",
        "\n",
        "    for key, value in features_cpu.items():\n",
        "        if key == 'amenities':\n",
        "            features_tensor[key] = value # Keep raw text\n",
        "        elif isinstance(value, dict):\n",
        "            features_tensor[key] = {}\n",
        "            for sub_key, sub_val in value.items():\n",
        "                dtype = torch.long if sub_key not in ['accommodates', 'geo_position'] else torch.float32\n",
        "                features_tensor[key][sub_key] = torch.from_numpy(sub_val).to(dtype=dtype)\n",
        "        else:\n",
        "            features_tensor[key] = torch.from_numpy(value).to(dtype=torch.float32)\n",
        "\n",
        "    return features_tensor\n",
        "\n",
        "def create_dataloaders(train_features_cpu, val_features_cpu, config: Config):\n",
        "    \"\"\"Creates high-performance, reproducible PyTorch DataLoaders.\"\"\"\n",
        "\n",
        "    # Tokenizer can still be on the GPU for speed, as it's used in the main process\n",
        "    tokenizer_model = SentenceTransformer('BAAI/bge-small-en-v1.5', device=config.DEVICE)\n",
        "\n",
        "    def custom_collate_fn(batch: list) -> dict:\n",
        "        amenities_texts = [item.pop('amenities_text') for item in batch]\n",
        "        collated_batch = {key: torch.stack([d[key] for d in batch]) for key in batch[0].keys()}\n",
        "        # The tokenizer is called, but its output remains on CPU by default\n",
        "        tokenized = tokenizer_model.tokenizer(\n",
        "            amenities_texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_tensors='pt',\n",
        "            max_length=128\n",
        "        )\n",
        "        collated_batch['amenities_tokens'] = tokenized\n",
        "        return collated_batch\n",
        "\n",
        "    train_dataset = AirbnbPriceDataset(train_features_cpu)\n",
        "    val_dataset = AirbnbPriceDataset(val_features_cpu)\n",
        "\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(config.SEED)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=custom_collate_fn,\n",
        "        generator=g,\n",
        "        pin_memory=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        dataset=val_dataset,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=custom_collate_fn,\n",
        "        pin_memory=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "    print(f\"DataLoaders created with pin_memory=True and num_workers=2.\")\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "xSMyFuNHnmQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Model Architecture**\n",
        "\n",
        "This is the `AdditiveAxisModel`, our core neural network. As detailed in `MODELING.md`, it's a multi-headed architecture where each \"head\" or sub-network is responsible for a distinct feature axis (Location, Size, etc.). The final price is the sum of contributions from each axis plus a global bias. This design makes the model's predictions inherently explainable."
      ],
      "metadata": {
        "id": "GBPciJiSnyF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdditiveAxisModel(nn.Module):\n",
        "    def __init__(self, processor: FeatureProcessor, device: str):\n",
        "        super().__init__()\n",
        "        self.vocabs, self.device = processor.vocabs, device\n",
        "        self.embed_neighbourhood = nn.Embedding(len(self.vocabs['neighbourhood_cleansed']), 16)\n",
        "        self.embed_property_type = nn.Embedding(len(self.vocabs['property_type']), 8)\n",
        "        self.embed_room_type = nn.Embedding(len(self.vocabs['room_type']), 4)\n",
        "        self.embed_bathrooms_type = nn.Embedding(len(self.vocabs['bathrooms_type']), 2)\n",
        "        self.embed_bedrooms = nn.Embedding(len(self.vocabs['bedrooms']), 4)\n",
        "        self.embed_beds = nn.Embedding(len(self.vocabs['beds']), 4)\n",
        "        self.embed_bathrooms_numeric = nn.Embedding(len(self.vocabs['bathrooms_numeric']), 4)\n",
        "        self.amenities_transformer = SentenceTransformer('BAAI/bge-small-en-v1.5', device=self.device)\n",
        "        for param in self.amenities_transformer.parameters(): param.requires_grad = False\n",
        "        self.loc_subnet = nn.Sequential(nn.Linear(48, 32), nn.ReLU(), nn.Linear(32, 1))\n",
        "        self.size_subnet = nn.Sequential(nn.Linear(27, 32), nn.ReLU(), nn.Linear(32, 1))\n",
        "        self.qual_subnet = nn.Sequential(nn.Linear(12, 32), nn.ReLU(), nn.Linear(32, 1))\n",
        "        self.amenities_subnet = nn.Linear(384, 1)\n",
        "        self.season_subnet = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 1))\n",
        "        self.global_bias = nn.Parameter(torch.randn(1))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, batch: dict) -> torch.Tensor:\n",
        "        # Location\n",
        "        loc_geo = batch['loc_geo_position']\n",
        "        loc_hood_embed = self.embed_neighbourhood(batch['loc_neighbourhood'])\n",
        "        loc_input = torch.cat([loc_geo, loc_hood_embed], dim=1)\n",
        "\n",
        "        # Size\n",
        "        size_embeds = [\n",
        "            self.embed_property_type(batch['size_property_type']),\n",
        "            self.embed_room_type(batch['size_room_type']),\n",
        "            self.embed_bathrooms_type(batch['size_bathrooms_type']),\n",
        "            self.embed_beds(batch['size_beds']),\n",
        "            self.embed_bedrooms(batch['size_bedrooms']),\n",
        "            self.embed_bathrooms_numeric(batch['size_bathrooms_numeric']),\n",
        "            batch['size_accommodates'].unsqueeze(1)\n",
        "            ]\n",
        "        size_input = torch.cat(size_embeds, dim=1)\n",
        "\n",
        "        # Quality\n",
        "        qual_inputs = [\n",
        "            batch['qual_review_scores_rating'].unsqueeze(1),\n",
        "            batch['qual_review_scores_cleanliness'].unsqueeze(1),\n",
        "            batch['qual_review_scores_checkin'].unsqueeze(1),\n",
        "            batch['qual_review_scores_communication'].unsqueeze(1),\n",
        "            batch['qual_review_scores_location'].unsqueeze(1),\n",
        "            batch['qual_review_scores_value'].unsqueeze(1),\n",
        "            batch['qual_host_response_rate'].unsqueeze(1),\n",
        "            batch['qual_host_acceptance_rate'].unsqueeze(1),\n",
        "            batch['qual_number_of_reviews_ltm'].unsqueeze(1),\n",
        "            batch['qual_host_is_superhost'].unsqueeze(1),\n",
        "            batch['qual_host_identity_verified'].unsqueeze(1),\n",
        "            batch['qual_instant_bookable'].unsqueeze(1)\n",
        "            ]\n",
        "        qual_input = torch.cat(qual_inputs, dim=1)\n",
        "\n",
        "        # Amenities\n",
        "        amenities_tokens = batch['amenities_tokens']\n",
        "        amenities_embed = self.amenities_transformer(amenities_tokens)['sentence_embedding']\n",
        "\n",
        "        # Get price contributions\n",
        "        p_loc = self.loc_subnet(loc_input)\n",
        "        p_size = self.size_subnet(size_input)\n",
        "        p_qual = self.qual_subnet(qual_input)\n",
        "        p_amenities = self.amenities_subnet(amenities_embed)\n",
        "        p_season = self.season_subnet(batch['season_cyclical'])\n",
        "\n",
        "        return (\n",
        "            self.global_bias\n",
        "            + p_loc\n",
        "            + p_size\n",
        "            + p_qual\n",
        "            + p_amenities\n",
        "            + p_season\n",
        "          ).squeeze(-1)"
      ],
      "metadata": {
        "id": "fPe4QfN0n01P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. Training Function**\n",
        "\n",
        "This function orchestrates the training and validation loops for a given number of epochs.\n"
      ],
      "metadata": {
        "id": "EdFvzcyOn4yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_model(\n",
        "#     model,\n",
        "#     train_loader: DataLoader,\n",
        "#     val_loader: DataLoader,\n",
        "#     optimizer: optim.Optimizer,\n",
        "#     config: Config\n",
        "#     ):\n",
        "#     \"\"\"Trains the model with step-based logging and validation.\"\"\"\n",
        "#     print(\"\\n--- Starting Model Training ---\")\n",
        "\n",
        "#     history = []\n",
        "#     total_steps = len(train_loader) * config.N_EPOCHS\n",
        "#     pbar = tqdm(total=total_steps, desc=\"Overall Training Progress\")\n",
        "\n",
        "#     global_step_count = 0\n",
        "\n",
        "#     for epoch in range(config.N_EPOCHS):\n",
        "#         model.train()\n",
        "\n",
        "#         for i, batch in enumerate(train_loader):\n",
        "#             # --- Training Step ---\n",
        "#             predictions = model(batch)\n",
        "#             targets = batch['target']\n",
        "#             weights = batch['sample_weight']\n",
        "#             loss = (weights * (predictions - targets)**2).mean()\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "#             optimizer.step()\n",
        "\n",
        "#             global_step_count += 1\n",
        "#             pbar.update(1)\n",
        "#             pbar.set_postfix({'Batch Loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "#             # --- Periodic Validation and Logging ---\n",
        "#             # Check if it's a logging step or the very last step of training\n",
        "#             if (global_step_count % config.LOG_EVERY_N_STEPS == 0) or (global_step_count == total_steps):\n",
        "#                 model.eval()\n",
        "#                 val_loss = 0.0\n",
        "#                 with torch.no_grad():\n",
        "#                     for val_batch in val_loader:\n",
        "#                         val_preds = model(val_batch)\n",
        "#                         val_targets = val_batch['target'].to(config.DEVICE)\n",
        "#                         val_weights = val_batch['sample_weight'].to(config.DEVICE)\n",
        "#                         val_batch_loss = (val_weights * (val_preds - val_targets)**2).mean()\n",
        "#                         val_loss += val_batch_loss.item()\n",
        "\n",
        "#                 avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "#                 # --- Update UI ---\n",
        "#                 epoch_float = epoch + (i + 1) / len(train_loader)\n",
        "#                 step_stats = {\n",
        "#                     'Steps': global_step_count,\n",
        "#                     'Epoch': epoch_float,\n",
        "#                     'Train RW-MSLE': np.sqrt(loss.item()), # Current train batch loss\n",
        "#                     'Val RW-MSLE': np.sqrt(avg_val_loss)\n",
        "#                 }\n",
        "#                 history.append(step_stats)\n",
        "\n",
        "#                 clear_output(wait=True)\n",
        "#                 history_df = pd.DataFrame(history).set_index('Steps')\n",
        "#                 display(history_df.style.format({'Epoch': '{:.2f}', 'Train RW-MSLE': '{:.4f}', 'Val RW-MSLE': '{:.4f}'}))\n",
        "\n",
        "#                 model.train() # Switch back to training mode\n",
        "\n",
        "#     pbar.close()\n",
        "#     print(\"\\n--- Training Complete ---\")\n",
        "#     return model, pd.DataFrame(history)\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    optimizer: optim.Optimizer,\n",
        "    config: Config\n",
        "    ):\n",
        "    \"\"\"Trains the model with step-based logging and validation.\"\"\"\n",
        "    print(\"\\n--- Starting Model Training ---\")\n",
        "\n",
        "    history = []\n",
        "    total_steps = len(train_loader) * config.N_EPOCHS\n",
        "    pbar = tqdm(total=total_steps, desc=\"Overall Training Progress\")\n",
        "\n",
        "    global_step_count = 0\n",
        "\n",
        "    for epoch in range(config.N_EPOCHS):\n",
        "        model.train()\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            # --- Re-introduce the efficient data transfer step ---\n",
        "            for key, value in batch.items():\n",
        "                if isinstance(value, torch.Tensor):\n",
        "                    batch[key] = value.to(config.DEVICE, non_blocking=True)\n",
        "                elif isinstance(value, dict): # For amenities_tokens\n",
        "                    for sub_key, sub_value in value.items():\n",
        "                        batch[key][sub_key] = sub_value.to(config.DEVICE, non_blocking=True)\n",
        "\n",
        "            targets = batch['target']\n",
        "            weights = batch['sample_weight']\n",
        "\n",
        "            # --- Training Step ---\n",
        "            predictions = model(batch)\n",
        "            loss = (weights * (predictions - targets)**2).mean()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            global_step_count += 1\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix({'Batch Loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "            # --- Periodic Validation and Logging ---\n",
        "            # Check if it's a logging step or the very last step of training\n",
        "            if (global_step_count % config.LOG_EVERY_N_STEPS == 0) or (global_step_count == total_steps):\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    for val_batch in val_loader:\n",
        "                        for key, value in val_batch.items():\n",
        "                            if isinstance(value, torch.Tensor):\n",
        "                              val_batch[key] = value.to(config.DEVICE, non_blocking=True)\n",
        "                            elif isinstance(value, dict):\n",
        "                              for sub_key, sub_value in value.items():\n",
        "                                  val_batch[key][sub_key] = sub_value.to(config.DEVICE, non_blocking=True)\n",
        "                        val_targets = val_batch['target']\n",
        "                        val_weights = val_batch['sample_weight']\n",
        "\n",
        "                        val_preds = model(val_batch)\n",
        "                        val_batch_loss = (val_weights * (val_preds - val_targets)**2).mean()\n",
        "                        val_loss += val_batch_loss.item()\n",
        "\n",
        "                avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "                # --- Update UI ---\n",
        "                epoch_float = epoch + (i + 1) / len(train_loader)\n",
        "                step_stats = {\n",
        "                    'Steps': global_step_count,\n",
        "                    'Epoch': epoch_float,\n",
        "                    'Train RW-MSLE': np.sqrt(loss.item()), # Current train batch loss\n",
        "                    'Val RW-MSLE': np.sqrt(avg_val_loss)\n",
        "                }\n",
        "                history.append(step_stats)\n",
        "\n",
        "                clear_output(wait=True)\n",
        "                history_df = pd.DataFrame(history).set_index('Steps')\n",
        "                display(history_df.style.format({'Epoch': '{:.2f}', 'Train RW-MSLE': '{:.4f}', 'Val RW-MSLE': '{:.4f}'}))\n",
        "\n",
        "                model.train() # Switch back to training mode\n",
        "\n",
        "    pbar.close()\n",
        "    print(\"\\n--- Training Complete ---\")\n",
        "    return model, pd.DataFrame(history)"
      ],
      "metadata": {
        "id": "I5L0rVz6n4Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8. Main Execution Function**\n",
        "\n",
        "This single cell runs the entire pipeline from start to finish using the settings defined in the `Config` class."
      ],
      "metadata": {
        "id": "joZIdabe1wA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_artifacts(artifacts: dict, config: Config):\n",
        "    \"\"\"Saves the essential training artifacts to a single file.\"\"\"\n",
        "    timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
        "    filename = f\"{config.CITY}_artifacts_{timestamp}.pt\"\n",
        "\n",
        "    # Define paths for local runtime and Google Drive\n",
        "    runtime_path = f\"./{filename}\"\n",
        "    drive_path = os.path.join(config.DRIVE_SAVE_PATH, filename)\n",
        "\n",
        "    # Ensure Google Drive directory exists\n",
        "    os.makedirs(config.DRIVE_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "    print(f\"\\nSaving artifacts to {runtime_path} and {drive_path}...\")\n",
        "    torch.save(artifacts, runtime_path)\n",
        "    torch.save(artifacts, drive_path)\n",
        "    print(\"Artifacts saved successfully.\")\n",
        "\n",
        "def main(config: Config):\n",
        "    \"\"\"Runs the end-to-end training pipeline.\"\"\"\n",
        "    # 1. Load and split data\n",
        "    train_df, val_df = load_and_split_data(config)\n",
        "\n",
        "    # 2. Process features and move to GPU\n",
        "    processor = FeatureProcessor()\n",
        "    processor.fit(train_df)\n",
        "    train_features_cpu = preprocess_and_tensorize_CPU(processor, train_df)\n",
        "    val_features_cpu = preprocess_and_tensorize_CPU(processor, val_df)\n",
        "\n",
        "    # 3. Create DataLoaders (pass CPU features)\n",
        "    train_loader, val_loader = create_dataloaders(train_features_cpu, val_features_cpu, config)\n",
        "\n",
        "    # 4. Initialize model and optimizer\n",
        "    model = AdditiveAxisModel(processor, device=config.DEVICE)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "    # 5. Run training\n",
        "    trained_model, training_history = train_model(model, train_loader, val_loader, optimizer, config)\n",
        "\n",
        "    # 6. Collate all artifacts into a single dictionary\n",
        "    artifacts = {\n",
        "        \"config\": config,\n",
        "        \"processor\": processor,\n",
        "        \"model_state_dict\": trained_model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"history\": training_history\n",
        "    }\n",
        "\n",
        "    # 7. Save artifacts and display final results\n",
        "    save_artifacts(artifacts, config)\n",
        "\n",
        "    print(\"\\n--- Final Training Results ---\")\n",
        "    display(training_history.style.format('{:.4f}').set_index('Steps'))\n",
        "\n",
        "    return artifacts"
      ],
      "metadata": {
        "id": "MX6c4H56n9pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **9. Final execution cell**\n",
        "\n",
        "Requires two steps-- First, instantiate a Config object (`config`, say), changing any attributes from the default as needed. Next, simply run `main(config)`"
      ],
      "metadata": {
        "id": "q6dclfe22Hka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the configuration\n",
        "config = Config()\n",
        "set_seed(config.SEED)\n",
        "\n",
        "print(f\"Configuration loaded:\")\n",
        "print(f\"Device: {config.DEVICE}\")\n",
        "print(f\"City: {config.CITY}\")\n",
        "print(f\"Seed: {config.SEED}\")\n",
        "print(f\"Batch Size: {config.BATCH_SIZE}\")\n",
        "print(f\"Learning Rate: {config.LEARNING_RATE}\")\n",
        "print(f\"Number of Epochs: {config.N_EPOCHS}\")\n",
        "print(f\"Logging Interval: {config.LOG_EVERY_N_STEPS}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Run the end-to-end training pipeline\n",
        "training_artifacts = main(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-ALhD09_2XJz",
        "outputId": "aa4f7d69-894d-46ba-e956-7b45312a0a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All random seeds set to 42.\n",
            "Configuration loaded:\n",
            "Device: cuda\n",
            "City: nyc\n",
            "Seed: 42\n",
            "Batch Size: 1024\n",
            "Learning Rate: 0.001\n",
            "Number of Epochs: 20\n",
            "Logging Interval: 10\n",
            "==================================================\n",
            "Loading dataset from: ./nyc_final_modeling_dataset.parquet\n",
            "Removed price outliers. New size: 81,643 records.\n",
            "Removed small strata. New size: 79,485 records.\n",
            "Split complete. Training: 63,588, Validation: 15,897\n",
            "\n",
            "--- Sample Record from Training Data ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                             0\n",
              "listing_id                                                  779010937952266773\n",
              "year_month                                                             2024-11\n",
              "target_price                                                              90.0\n",
              "estimated_occupancy_rate                                              0.066667\n",
              "latitude                                                              40.63478\n",
              "longitude                                                             -73.9501\n",
              "neighbourhood_cleansed                                                Flatbush\n",
              "property_type                                               Entire rental unit\n",
              "room_type                                                      Entire home/apt\n",
              "accommodates                                                                 2\n",
              "bedrooms                                                                   1.0\n",
              "beds                                                                       1.0\n",
              "bathrooms_numeric                                                          1.0\n",
              "bathrooms_type                                                         private\n",
              "amenities                    [\"Fire extinguisher\", \"Smoke alarm\", \"Gas stov...\n",
              "review_scores_rating                                                       4.8\n",
              "review_scores_cleanliness                                                  4.7\n",
              "review_scores_checkin                                                      4.8\n",
              "review_scores_communication                                                4.9\n",
              "review_scores_location                                                     4.6\n",
              "review_scores_value                                                        4.7\n",
              "number_of_reviews_ltm                                                        3\n",
              "host_is_superhost                                                         True\n",
              "host_response_rate                                                         1.0\n",
              "host_acceptance_rate                                                      0.89\n",
              "host_identity_verified                                                    True\n",
              "instant_bookable                                                         False\n",
              "month                                                                       11\n",
              "price_bin                                                                    0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b56441e-8e26-4330-9c19-1b498a35f4e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>listing_id</th>\n",
              "      <td>779010937952266773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year_month</th>\n",
              "      <td>2024-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target_price</th>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>estimated_occupancy_rate</th>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>latitude</th>\n",
              "      <td>40.63478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>longitude</th>\n",
              "      <td>-73.9501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neighbourhood_cleansed</th>\n",
              "      <td>Flatbush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property_type</th>\n",
              "      <td>Entire rental unit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>room_type</th>\n",
              "      <td>Entire home/apt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accommodates</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bedrooms</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beds</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bathrooms_numeric</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bathrooms_type</th>\n",
              "      <td>private</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amenities</th>\n",
              "      <td>[\"Fire extinguisher\", \"Smoke alarm\", \"Gas stov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_scores_rating</th>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_scores_cleanliness</th>\n",
              "      <td>4.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_scores_checkin</th>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_scores_communication</th>\n",
              "      <td>4.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_scores_location</th>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_scores_value</th>\n",
              "      <td>4.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number_of_reviews_ltm</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>host_is_superhost</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>host_response_rate</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>host_acceptance_rate</th>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>host_identity_verified</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>instant_bookable</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>month</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price_bin</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b56441e-8e26-4330-9c19-1b498a35f4e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b56441e-8e26-4330-9c19-1b498a35f4e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b56441e-8e26-4330-9c19-1b498a35f4e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-252fb58a-5c8f-47ba-862c-f09e0657a110\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-252fb58a-5c8f-47ba-862c-f09e0657a110')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-252fb58a-5c8f-47ba-862c-f09e0657a110 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"training_artifacts = main(config)\",\n  \"rows\": 29,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          779010937952266773,\n          3,\n          4.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders created with pin_memory=True and num_workers=2.\n",
            "\n",
            "--- Starting Model Training ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Overall Training Progress:   0%|          | 0/1260 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/tmp/ipython-input-1781483063.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['loc_geo_position'] = torch.tensor(self.features['location']['geo_position'][index], dtype=torch.float32)\n",
            "/tmp/ipython-input-1781483063.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['loc_neighbourhood'] = torch.tensor(self.features['location']['neighbourhood'][index], dtype=torch.long)\n",
            "/tmp/ipython-input-1781483063.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['loc_geo_position'] = torch.tensor(self.features['location']['geo_position'][index], dtype=torch.float32)\n",
            "/tmp/ipython-input-1781483063.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[f'size_{k}'] = torch.tensor(v[index], dtype=dtype)\n",
            "/tmp/ipython-input-1781483063.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['loc_neighbourhood'] = torch.tensor(self.features['location']['neighbourhood'][index], dtype=torch.long)\n",
            "/tmp/ipython-input-1781483063.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[f'qual_{k}'] = torch.tensor(v[index], dtype=torch.float32)\n",
            "/tmp/ipython-input-1781483063.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[f'size_{k}'] = torch.tensor(v[index], dtype=dtype)\n",
            "/tmp/ipython-input-1781483063.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item[f'qual_{k}'] = torch.tensor(v[index], dtype=torch.float32)\n",
            "/tmp/ipython-input-1781483063.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['season_cyclical'] = torch.tensor(self.features['seasonality']['cyclical'][index], dtype=torch.float32)\n",
            "/tmp/ipython-input-1781483063.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['target'] = torch.tensor(self.features['target_log_price'][index], dtype=torch.float32)\n",
            "/tmp/ipython-input-1781483063.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['season_cyclical'] = torch.tensor(self.features['seasonality']['cyclical'][index], dtype=torch.float32)\n",
            "/tmp/ipython-input-1781483063.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['sample_weight'] = torch.tensor(self.features['sample_weight'][index], dtype=torch.float32)\n",
            "/tmp/ipython-input-1781483063.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['target'] = torch.tensor(self.features['target_log_price'][index], dtype=torch.float32)\n",
            "/tmp/ipython-input-1781483063.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['sample_weight'] = torch.tensor(self.features['sample_weight'][index], dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1293461057.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Run the end-to-end training pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtraining_artifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-152939801.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# 5. Run training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# 6. Collate all artifacts into a single dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1581783203.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, config)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;31m# --- Training Step ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3806591564.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Amenities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mamenities_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amenities_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mamenities_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamenities_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamenities_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence_embedding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Get price contributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule_kwarg_keys\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"forward_kwargs\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                 }\n\u001b[0;32m-> 1175\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mtrans_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    933\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    936\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2544\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2546\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (This cell replaces your existing Dataloader Creation cell)\n",
        "\n",
        "# --- DEBUG: Function to print tensor devices in a nested dictionary ---\n",
        "def print_tensor_devices(d, prefix=\"\"):\n",
        "    for k, v in d.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            print(f\"{prefix}{k}: {v.device}\")\n",
        "        elif isinstance(v, dict):\n",
        "            print_tensor_devices(v, prefix=f\"{k}.\")\n",
        "\n",
        "def preprocess_and_tensorize(processor, df, device):\n",
        "    \"\"\"Applies the feature processor and moves all resulting tensors to the specified device.\"\"\"\n",
        "    features_cpu = processor.transform(df)\n",
        "    features_gpu = {}\n",
        "    for key, value in features_cpu.items():\n",
        "        if key == 'amenities':\n",
        "            features_gpu[key] = value\n",
        "        elif isinstance(value, dict):\n",
        "            features_gpu[key] = {}\n",
        "            for sub_key, sub_val in value.items():\n",
        "                dtype = torch.long if sub_key != 'accommodates' and 'geo_position' not in sub_key else torch.float32\n",
        "                features_gpu[key][sub_key] = torch.from_numpy(sub_val).to(device, dtype=dtype)\n",
        "        else:\n",
        "            features_gpu[key] = torch.from_numpy(value).to(device, dtype=torch.float32)\n",
        "\n",
        "    print(\"\\n--- DEBUG: After preprocess_and_tensorize ---\")\n",
        "    print(\"Verifying devices of pre-loaded tensors...\")\n",
        "    print_tensor_devices(features_gpu)\n",
        "    return features_gpu\n",
        "\n",
        "def create_dataloaders_DEBUG(train_features_gpu, val_features_gpu, config: Config):\n",
        "    \"\"\"Creates DataLoaders with a debug-enabled collate function.\"\"\"\n",
        "\n",
        "    tokenizer_model = SentenceTransformer('BAAI/bge-small-en-v1.5', device=config.DEVICE)\n",
        "\n",
        "    def custom_collate_fn_DEBUG(batch: list) -> dict:\n",
        "        amenities_texts = [item.pop('amenities_text') for item in batch]\n",
        "        collated_batch = {key: torch.stack([d[key] for d in batch]) for key in batch[0].keys()}\n",
        "\n",
        "        # Tokenizer creates new tensors. Let's see what device they are on.\n",
        "        tokenized = tokenizer_model.tokenizer(\n",
        "            amenities_texts, padding=True, truncation=True, return_tensors='pt', max_length=128\n",
        "        )\n",
        "        collated_batch['amenities_tokens'] = tokenized\n",
        "\n",
        "        # --- DEBUG PRINT ---\n",
        "        if not hasattr(custom_collate_fn_DEBUG, '_printed'):\n",
        "            print(\"\\n--- DEBUG: Inside custom_collate_fn ---\")\n",
        "            print(\"Verifying devices of tensors in the FIRST collated batch:\")\n",
        "            print_tensor_devices(collated_batch)\n",
        "            custom_collate_fn_DEBUG._printed = True # Print only once\n",
        "\n",
        "        return collated_batch\n",
        "\n",
        "    train_dataset = AirbnbPriceDataset(train_features_gpu)\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=config.BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn_DEBUG) # Shuffle=False for deterministic debug\n",
        "\n",
        "    print(f\"\\nDataLoaders created. Debug prints are enabled.\")\n",
        "    return train_loader"
      ],
      "metadata": {
        "id": "DawDI06vdupP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (This cell replaces your existing Model Architecture cell)\n",
        "\n",
        "class AdditiveAxisModel_DEBUG(nn.Module):\n",
        "    # __init__ is identical to your original AdditiveAxisModel\n",
        "    def __init__(self, processor: FeatureProcessor, device: str):\n",
        "        super().__init__()\n",
        "        self.vocabs, self.device = processor.vocabs, device\n",
        "        self.embed_neighbourhood = nn.Embedding(len(self.vocabs['neighbourhood_cleansed']), 16)\n",
        "        self.embed_property_type = nn.Embedding(len(self.vocabs['property_type']), 8)\n",
        "        self.embed_room_type = nn.Embedding(len(self.vocabs['room_type']), 4)\n",
        "        self.embed_bathrooms_type = nn.Embedding(len(self.vocabs['bathrooms_type']), 2)\n",
        "        self.embed_bedrooms = nn.Embedding(len(self.vocabs['bedrooms']), 4)\n",
        "        self.embed_beds = nn.Embedding(len(self.vocabs['beds']), 4)\n",
        "        self.embed_bathrooms_numeric = nn.Embedding(len(self.vocabs['bathrooms_numeric']), 4)\n",
        "        self.amenities_transformer = SentenceTransformer('BAAI/bge-small-en-v1.5', device=self.device)\n",
        "        for param in self.amenities_transformer.parameters(): param.requires_grad = False\n",
        "        self.loc_subnet = nn.Sequential(nn.Linear(48, 32), nn.ReLU(), nn.Linear(32, 1))\n",
        "        self.size_subnet = nn.Sequential(nn.Linear(27, 32), nn.ReLU(), nn.Linear(32, 1))\n",
        "        self.qual_subnet = nn.Sequential(nn.Linear(12, 32), nn.ReLU(), nn.Linear(32, 1))\n",
        "        self.amenities_subnet = nn.Linear(384, 1)\n",
        "        self.season_subnet = nn.Sequential(nn.Linear(2, 16), nn.ReLU(), nn.Linear(16, 1))\n",
        "        self.global_bias = nn.Parameter(torch.randn(1))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, batch: dict) -> torch.Tensor:\n",
        "        # --- DEBUG PRINT ---\n",
        "        print(\"\\n--- DEBUG: Inside model.forward() ---\")\n",
        "        print(f\"Model's own device: {self.device}\")\n",
        "        print(\"Devices of tensors received in the batch:\")\n",
        "        print_tensor_devices(batch)\n",
        "\n",
        "        # --- The rest of the forward pass ---\n",
        "        loc_geo = batch['loc_geo_position']\n",
        "        # ... (rest of the forward pass is identical)\n",
        "        loc_hood_embed = self.embed_neighbourhood(batch['loc_neighbourhood'])\n",
        "        loc_input = torch.cat([loc_geo, loc_hood_embed], dim=1)\n",
        "        size_embeds = [self.embed_property_type(batch['size_property_type']), self.embed_room_type(batch['size_room_type']), self.embed_bathrooms_type(batch['size_bathrooms_type']), self.embed_beds(batch['size_beds']), self.embed_bedrooms(batch['size_bedrooms']), self.embed_bathrooms_numeric(batch['size_bathrooms_numeric']), batch['size_accommodates'].unsqueeze(1)]\n",
        "        size_input = torch.cat(size_embeds, dim=1)\n",
        "        qual_inputs = [batch[f'qual_{col}'].unsqueeze(1) for col in [\"review_scores_rating\", \"review_scores_cleanliness\", \"review_scores_checkin\", \"review_scores_communication\", \"review_scores_location\", \"review_scores_value\", \"host_response_rate\", \"host_acceptance_rate\", \"number_of_reviews_ltm\", \"host_is_superhost\", \"host_identity_verified\", \"instant_bookable\"]]\n",
        "        qual_input = torch.cat(qual_inputs, dim=1)\n",
        "        amenities_embed = self.amenities_transformer(batch['amenities_tokens'])['sentence_embedding']\n",
        "        p_loc = self.loc_subnet(loc_input)\n",
        "        p_size = self.size_subnet(size_input)\n",
        "        p_qual = self.qual_subnet(qual_input)\n",
        "        p_amenities = self.amenities_subnet(amenities_embed)\n",
        "        p_season = self.season_subnet(batch['season_cyclical'])\n",
        "        return (self.global_bias + p_loc + p_size + p_qual + p_amenities + p_season).squeeze(-1)"
      ],
      "metadata": {
        "id": "cGHdhosRfIPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (This replaces your existing main execution cell)\n",
        "\n",
        "def main_DEBUG(config: Config):\n",
        "    \"\"\"Runs a single-batch debug pipeline to trace tensor devices.\"\"\"\n",
        "    # 1. Load data\n",
        "    train_df, _ = load_and_split_data(config)\n",
        "\n",
        "    # 2. Process features and move to GPU\n",
        "    processor = FeatureProcessor()\n",
        "    processor.fit(train_df)\n",
        "    train_features_gpu = preprocess_and_tensorize(processor, train_df, config.DEVICE)\n",
        "\n",
        "    # 3. Create DEBUG DataLoader\n",
        "    train_loader_debug = create_dataloaders_DEBUG(train_features_gpu, {}, config)\n",
        "\n",
        "    # 4. Initialize DEBUG model\n",
        "    model_debug = AdditiveAxisModel_DEBUG(processor, device=config.DEVICE)\n",
        "    model_debug.eval()\n",
        "\n",
        "    # 5. Get a single batch\n",
        "    print(\"\\n--- Getting a single batch from the DataLoader ---\")\n",
        "    first_batch = next(iter(train_loader_debug))\n",
        "\n",
        "    # 6. Attempt a single forward pass and catch the error\n",
        "    print(\"\\n--- Attempting a single forward pass ---\")\n",
        "    with torch.no_grad():\n",
        "        output = model_debug(first_batch)\n",
        "    print(\"\\nSUCCESS: Forward pass completed without error.\")\n",
        "    print(f\"Output tensor device: {output.device}\")\n",
        "\n",
        "# Run the debug pipeline\n",
        "main_DEBUG(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BAs7Q401fKFU",
        "outputId": "87f8c8e8-a592-4dbb-c632-574b2d1eaf3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from: ./nyc_final_modeling_dataset.parquet\n",
            "Removed price outliers. New size: 81,643 records.\n",
            "Removed small strata. New size: 79,485 records.\n",
            "Split complete. Training: 63,588, Validation: 15,897\n",
            "\n",
            "--- Sample Record from Training Data ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                             0\n",
              "listing_id                                                  779010937952266773\n",
              "year_month                                                             2024-11\n",
              "target_price                                                              90.0\n",
              "estimated_occupancy_rate                                              0.066667\n",
              "latitude                                                              40.63478\n",
              "longitude                                                             -73.9501\n",
              "neighbourhood_cleansed                                                Flatbush\n",
              "property_type                                               Entire rental unit\n",
              "room_type                                                      Entire home/apt\n",
              "accommodates                                                                 2\n",
              "bedrooms                                                                   1.0\n",
              "beds                                                                       1.0\n",
              "bathrooms_numeric                                                          1.0\n",
              "bathrooms_type                                                         private\n",
              "amenities                    [\"Fire extinguisher\", \"Smoke alarm\", \"Gas stov...\n",
              "review_scores_rating                                                       4.8\n",
              "review_scores_cleanliness                                                  4.7\n",
              "review_scores_checkin                                                      4.8\n",
              "review_scores_communication                                                4.9\n",
              "review_scores_location                                                     4.6\n",
              "review_scores_value                                                        4.7\n",
              "number_of_reviews_ltm                                                        3\n",
              "host_is_superhost                                                         True\n",
              "host_response_rate                                                         1.0\n",
              "host_acceptance_rate                                                      0.89\n",
              "host_identity_verified                                                    True\n",
              "instant_bookable                                                         False\n",
              "month                                                                       11\n",
              "price_bin                                                                    0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29c39db1-d03a-4288-9e33-dc3cb2b3b47a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>listing_id</th>\n",
              "      <td>779010937952266773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year_month</th>\n",
              "      <td>2024-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target_price</th>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>estimated_occupancy_rate</th>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>latitude</th>\n",
              "      <td>40.63478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>longitude</th>\n",
              "      <td>-73.9501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neighbourhood_cleansed</th>\n",
              "      <td>Flatbush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property_type</th>\n",
              "      <td>Entire rental unit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>room_type</th>\n",
              "      <td>Entire home/apt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accommodates</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bedrooms</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beds</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bathrooms_numeric</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bathrooms_type</th>\n",
              "      <td>private</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amenities</th>\n",
              "      <td>[\"Fire extinguisher\", \"Smoke alarm\", \"Gas stov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_scores_rating</th>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_scores_cleanliness</th>\n",
              "      <td>4.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_scores_checkin</th>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_scores_communication</th>\n",
              "      <td>4.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_scores_location</th>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_scores_value</th>\n",
              "      <td>4.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number_of_reviews_ltm</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>host_is_superhost</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>host_response_rate</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>host_acceptance_rate</th>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>host_identity_verified</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>instant_bookable</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>month</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price_bin</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29c39db1-d03a-4288-9e33-dc3cb2b3b47a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29c39db1-d03a-4288-9e33-dc3cb2b3b47a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29c39db1-d03a-4288-9e33-dc3cb2b3b47a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d2963b50-1dd9-4a59-8f98-51e4f4951670\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2963b50-1dd9-4a59-8f98-51e4f4951670')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d2963b50-1dd9-4a59-8f98-51e4f4951670 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"main_DEBUG(config)\",\n  \"rows\": 29,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          779010937952266773,\n          3,\n          4.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- DEBUG: After preprocess_and_tensorize ---\n",
            "Verifying devices of pre-loaded tensors...\n",
            "location.geo_position: cuda:0\n",
            "location.neighbourhood: cuda:0\n",
            "size_capacity.property_type: cuda:0\n",
            "size_capacity.room_type: cuda:0\n",
            "size_capacity.bathrooms_type: cuda:0\n",
            "size_capacity.bedrooms: cuda:0\n",
            "size_capacity.beds: cuda:0\n",
            "size_capacity.bathrooms_numeric: cuda:0\n",
            "size_capacity.accommodates: cuda:0\n",
            "quality.review_scores_rating: cuda:0\n",
            "quality.review_scores_cleanliness: cuda:0\n",
            "quality.review_scores_checkin: cuda:0\n",
            "quality.review_scores_communication: cuda:0\n",
            "quality.review_scores_location: cuda:0\n",
            "quality.review_scores_value: cuda:0\n",
            "quality.host_response_rate: cuda:0\n",
            "quality.host_acceptance_rate: cuda:0\n",
            "quality.number_of_reviews_ltm: cuda:0\n",
            "quality.host_is_superhost: cuda:0\n",
            "quality.host_identity_verified: cuda:0\n",
            "quality.instant_bookable: cuda:0\n",
            "seasonality.cyclical: cuda:0\n",
            "target_log_price: cuda:0\n",
            "sample_weight: cuda:0\n",
            "\n",
            "DataLoaders created. Debug prints are enabled.\n",
            "\n",
            "--- Getting a single batch from the DataLoader ---\n",
            "\n",
            "--- DEBUG: Inside custom_collate_fn ---\n",
            "Verifying devices of tensors in the FIRST collated batch:\n",
            "loc_geo_position: cuda:0\n",
            "loc_neighbourhood: cuda:0\n",
            "size_property_type: cuda:0\n",
            "size_room_type: cuda:0\n",
            "size_bathrooms_type: cuda:0\n",
            "size_bedrooms: cuda:0\n",
            "size_beds: cuda:0\n",
            "size_bathrooms_numeric: cuda:0\n",
            "size_accommodates: cuda:0\n",
            "qual_review_scores_rating: cuda:0\n",
            "qual_review_scores_cleanliness: cuda:0\n",
            "qual_review_scores_checkin: cuda:0\n",
            "qual_review_scores_communication: cuda:0\n",
            "qual_review_scores_location: cuda:0\n",
            "qual_review_scores_value: cuda:0\n",
            "qual_host_response_rate: cuda:0\n",
            "qual_host_acceptance_rate: cuda:0\n",
            "qual_number_of_reviews_ltm: cuda:0\n",
            "qual_host_is_superhost: cuda:0\n",
            "qual_host_identity_verified: cuda:0\n",
            "qual_instant_bookable: cuda:0\n",
            "season_cyclical: cuda:0\n",
            "target: cuda:0\n",
            "sample_weight: cuda:0\n",
            "\n",
            "--- Attempting a single forward pass ---\n",
            "\n",
            "--- DEBUG: Inside model.forward() ---\n",
            "Model's own device: cuda\n",
            "Devices of tensors received in the batch:\n",
            "loc_geo_position: cuda:0\n",
            "loc_neighbourhood: cuda:0\n",
            "size_property_type: cuda:0\n",
            "size_room_type: cuda:0\n",
            "size_bathrooms_type: cuda:0\n",
            "size_bedrooms: cuda:0\n",
            "size_beds: cuda:0\n",
            "size_bathrooms_numeric: cuda:0\n",
            "size_accommodates: cuda:0\n",
            "qual_review_scores_rating: cuda:0\n",
            "qual_review_scores_cleanliness: cuda:0\n",
            "qual_review_scores_checkin: cuda:0\n",
            "qual_review_scores_communication: cuda:0\n",
            "qual_review_scores_location: cuda:0\n",
            "qual_review_scores_value: cuda:0\n",
            "qual_host_response_rate: cuda:0\n",
            "qual_host_acceptance_rate: cuda:0\n",
            "qual_number_of_reviews_ltm: cuda:0\n",
            "qual_host_is_superhost: cuda:0\n",
            "qual_host_identity_verified: cuda:0\n",
            "qual_instant_bookable: cuda:0\n",
            "season_cyclical: cuda:0\n",
            "target: cuda:0\n",
            "sample_weight: cuda:0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2126646931.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Run the debug pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmain_DEBUG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2126646931.py\u001b[0m in \u001b[0;36mmain_DEBUG\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Attempting a single forward pass ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSUCCESS: Forward pass completed without error.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Output tensor device: {output.device}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3947796058.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mqual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'qual_{col}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"review_scores_rating\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"review_scores_cleanliness\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"review_scores_checkin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"review_scores_communication\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"review_scores_location\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"review_scores_value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"host_response_rate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"host_acceptance_rate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"number_of_reviews_ltm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"host_is_superhost\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"host_identity_verified\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"instant_bookable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mqual_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqual_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mamenities_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamenities_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amenities_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence_embedding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mp_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc_subnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mp_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_subnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule_kwarg_keys\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"forward_kwargs\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                 }\n\u001b[0;32m-> 1175\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mtrans_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    933\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    936\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2544\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2546\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I-N0F_RUfM7o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}