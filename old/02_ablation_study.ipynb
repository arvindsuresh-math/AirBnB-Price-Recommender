{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cc78fb2",
   "metadata": {},
   "source": [
    "# 2. Additive Model Ablation Study\n",
    "\n",
    "### Objective\n",
    "\n",
    "To quantify the importance and contribution of each specialized sub-network in our `AdditiveModel`, we conduct a comprehensive ablation study.\n",
    "\n",
    "An ablation study involves systematically removing one component of the model at a time, retraining the model from scratch, and measuring the impact on its performance. A significant drop in performance (i.e., an increase in RMSE or MAPE) when an axis is removed indicates that the axis is highly important for the model's predictive accuracy.\n",
    "\n",
    "This process allows us to validate our architectural choices and understand which features are the most critical drivers of price in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0dc9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Environment Setup (for Google Colab) ---\n",
    "from google.colab import drive, userdata\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "print(\"--- Setting up Environment ---\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# IMPORTANT: Make sure this path matches your project folder\n",
    "PROJECT_PATH = '/content/drive/MyDrive/Airbnb_Price_Project'\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# --- Standard and Third-Party Library Imports ---\n",
    "import pandas as pd\n",
    "\n",
    "# --- Imports from Custom Project Scripts ---\n",
    "print(\"\\n--- Importing Custom Modules ---\")\n",
    "from config import config\n",
    "from data_processing import load_and_split_data, FeatureProcessor, create_dataloaders\n",
    "from model import AblationAdditiveModel # Specifically import the ablation model\n",
    "from train import run_ablation_experiment # Import the high-level experiment runner\n",
    "\n",
    "print(\"\\nSetup and imports complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f73497",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n",
    "\n",
    "For a fair and controlled experiment, the data pipeline must remain identical for every ablation run. We prepare the `train_loader` and `val_loader` once at the beginning. These exact same data loaders will then be passed to each training run, ensuring that the only variable changing between experiments is the model's architecture (i.e., which axis is being excluded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split the data\n",
    "train_df, val_df, neighborhood_log_means, _, _ = load_and_split_data(config)\n",
    "\n",
    "# Instantiate and fit the feature processor\n",
    "processor = FeatureProcessor(config)\n",
    "processor.fit(train_df)\n",
    "\n",
    "# Transform datasets into feature dictionaries\n",
    "train_features = processor.transform(train_df, neighborhood_log_means)\n",
    "val_features = processor.transform(val_df, neighborhood_log_means)\n",
    "\n",
    "# Create the reusable PyTorch DataLoaders\n",
    "train_loader, val_loader = create_dataloaders(train_features, val_features, config)\n",
    "\n",
    "print(\"\\nData pipeline complete. DataLoaders will be reused for all experiments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42b3b73",
   "metadata": {},
   "source": [
    "## Running the Ablation Experiments\n",
    "\n",
    "We now proceed with the core of the study. The process is as follows:\n",
    "\n",
    "1.  **Establish a Baseline:** We first run an experiment with **no axes excluded**. This trains the full `AdditiveModel` and gives us the baseline performance metric against which all other runs will be compared.\n",
    "2.  **Iterate and Ablate:** We define a list of all six model axes. We then loop through this list, and for each axis, we execute our `run_ablation_experiment` function. This powerful wrapper, imported from `train.py`, handles the entire workflow for a single run:\n",
    "    - Instantiates the `AblationAdditiveModel`, telling it which axis to exclude.\n",
    "    - Sets up the optimizer and scheduler.\n",
    "    - Runs the full training loop with early stopping.\n",
    "    - Evaluates the final model and returns a dictionary of performance metrics.\n",
    "3.  **Collect Results:** The metrics from each run are collected in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the results from each experimental run\n",
    "ablation_results = []\n",
    "\n",
    "# --- Run 0: Establish the baseline with the full model ---\n",
    "baseline_metrics = run_ablation_experiment(\n",
    "    exclude_axes=[], # An empty list means all axes are included\n",
    "    config=config,\n",
    "    processor=processor,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader\n",
    ")\n",
    "ablation_results.append(baseline_metrics)\n",
    "\n",
    "# --- Define the axes to remove one by one ---\n",
    "axes_to_ablate = [\n",
    "    'location',\n",
    "    'size_capacity',\n",
    "    'quality',\n",
    "    'amenities',\n",
    "    'description',\n",
    "    'seasonality'\n",
    "]\n",
    "\n",
    "# --- Loop through each axis and run an experiment ---\n",
    "for axis in axes_to_ablate:\n",
    "    experiment_metrics = run_ablation_experiment(\n",
    "        exclude_axes=[axis], # Exclude the current axis\n",
    "        config=config,\n",
    "        processor=processor,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader\n",
    "    )\n",
    "    ablation_results.append(experiment_metrics)\n",
    "\n",
    "print(\"\\n\\nAll ablation experiments have been completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d38c6e",
   "metadata": {},
   "source": [
    "## Compiling and Saving Results\n",
    "\n",
    "With all experiments complete, we compile the collected list of metric dictionaries into a single, clean pandas DataFrame. This table provides a clear overview of the study's findings.\n",
    "\n",
    "We display the summary directly in the notebook and then save the DataFrame to a timestamped CSV file in our artifacts directory. This file will be loaded by our `04_results_and_analysis.ipynb` notebook to generate visualizations and draw final conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionaries into a DataFrame\n",
    "results_df = pd.DataFrame(ablation_results)\n",
    "\n",
    "# Format MAPE columns into percentages for easier reading\n",
    "results_df['train_mape_pct'] = results_df['train_mape'] * 100\n",
    "results_df['val_mape_pct'] = results_df['val_mape'] * 100\n",
    "\n",
    "# Define the columns to display and their order\n",
    "display_cols = ['excluded_axes', 'train_rmse', 'val_rmse', 'train_mape_pct', 'val_mape_pct']\n",
    "\n",
    "# --- Final Summary of Results ---\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(f\"{'ABLATION STUDY SUMMARY':^80}\")\n",
    "print(\"=\"*80)\n",
    "print(results_df[display_cols].to_string(index=False, float_format=\"%.4f\"))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- Save the results DataFrame to a CSV file ---\n",
    "timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f\"{config['CITY']}_ablation_results_{timestamp}.csv\"\n",
    "save_path = os.path.join(config['DRIVE_SAVE_PATH'], filename)\n",
    "\n",
    "# Ensure the target directory exists\n",
    "os.makedirs(config['DRIVE_SAVE_PATH'], exist_ok=True)\n",
    "\n",
    "# Save the complete DataFrame\n",
    "results_df.to_csv(save_path, index=False, float_format=\"%.6f\")\n",
    "\n",
    "print(f\"\\nAblation study results successfully saved to:\\n{save_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
