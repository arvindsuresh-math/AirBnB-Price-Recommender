{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arvindsuresh-math/Fall-2025-Team-Big-Data/blob/main/notebooks/fully_connected_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "123ef2b6",
      "metadata": {
        "id": "123ef2b6"
      },
      "source": [
        "### 0. Setup and Installations\n",
        "\n",
        "This cell prepares the Google Colab environment by mounting Google Drive, changing the working directory to our project folder to ensure all custom modules can be imported, installing the required Python packages, and handling Hugging Face authentication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5867b3b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5867b3b8",
        "outputId": "59c1e66d-ef2b-44c6-aab3-7411af6cf4b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Current working directory: /content/drive/MyDrive/Airbnb_Price_Project\n"
          ]
        }
      ],
      "source": [
        "# --- Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Change Directory to Project Folder ---\n",
        "# This is a crucial step that makes all local imports work seamlessly\n",
        "import os\n",
        "# IMPORTANT: Make sure this path matches the location of your project folder in Google Drive\n",
        "PROJECT_PATH = '/content/drive/MyDrive/Airbnb_Price_Project'\n",
        "os.chdir(PROJECT_PATH)\n",
        "print(f\"Current working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "110448be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "110448be",
        "outputId": "13c43f82-de8c-467f-bfa5-cf069f63c849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting Hugging Face login...\n",
            "Hugging Face login successful.\n"
          ]
        }
      ],
      "source": [
        "# --- Hugging Face Authentication ---\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "print(\"\\nAttempting Hugging Face login...\")\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"Hugging Face login successful.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not log in. Please ensure 'HF_TOKEN' is a valid secret. Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f2f17212",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2f17212",
        "outputId": "3236e325-586f-412d-9e98-e74d566a0cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.12/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# --- Install Dependencies ---\n",
        "!pip install pandas\n",
        "!pip install pyarrow\n",
        "!pip install sentence-transformers\n",
        "!pip install scikit-learn\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install transformers\n",
        "!pip install matplotlib\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "0ZwzUyQRx8Z6"
      },
      "id": "0ZwzUyQRx8Z6",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AirbnbPriceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset to handle feature collation and on-the-fly tokenization.\n",
        "    \"\"\"\n",
        "    def __init__(self, features: dict, tokenizer: AutoTokenizer):\n",
        "        self.features = features\n",
        "        self.tokenizer = tokenizer\n",
        "        self.n_samples = len(features['target_price'])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.n_samples\n",
        "\n",
        "    def __getitem__(self, index: int) -> dict:\n",
        "        item = {\n",
        "            'loc_geo_position': torch.tensor(self.features['location']['geo_position'][index], dtype=torch.float32),\n",
        "            'season_cyclical': torch.tensor(self.features['seasonality']['cyclical'][index], dtype=torch.float32),\n",
        "            'target_price': torch.tensor(self.features['target_price'][index], dtype=torch.float32),\n",
        "            'target_log_deviation': torch.tensor(self.features['target_log_deviation'][index], dtype=torch.float32),\n",
        "            'neighborhood_log_mean': torch.tensor(self.features['neighborhood_log_mean'][index], dtype=torch.float32),\n",
        "        }\n",
        "        for k, v in self.features['size_capacity'].items():\n",
        "            dtype = torch.long if k in ['property_type', 'room_type'] else torch.float32\n",
        "            item[f'size_{k}'] = torch.tensor(v[index], dtype=dtype)\n",
        "        for k, v in self.features['quality'].items():\n",
        "            item[f'qual_{k}'] = torch.tensor(v[index], dtype=torch.float32)\n",
        "\n",
        "        item['amenities_tokens'] = self.tokenizer(\n",
        "            self.features['amenities_text'][index], padding='max_length', truncation=True,\n",
        "            max_length=128, return_tensors=\"pt\"\n",
        "        )\n",
        "        item['description_tokens'] = self.tokenizer(\n",
        "            self.features['description_text'][index], padding='max_length', truncation=True,\n",
        "            max_length=256, return_tensors=\"pt\"\n",
        "        )\n",
        "        return item"
      ],
      "metadata": {
        "id": "D9C-GigZx_uq"
      },
      "id": "D9C-GigZx_uq",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineFCNV2(nn.Module):\n",
        "    \"\"\"\n",
        "    A regularized, smaller Fully Connected Network to combat overfitting.\n",
        "\n",
        "    Changes from the original baseline:\n",
        "    1. Reduced layer sizes from (256 -> 64) to (128 -> 32) to decrease model capacity.\n",
        "    2. Added Dropout layers after each main block for regularization.\n",
        "    3. Dropout rate is configurable via the __init__ method.\n",
        "    \"\"\"\n",
        "    def __init__(self, processor: 'FeatureProcessor', config: dict, dropout_rate: float = 0.4):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.device = self.config['DEVICE']\n",
        "\n",
        "        # --- Embeddings & Encoders (same as original model) ---\n",
        "        self.embed_property_type = nn.Embedding(len(processor.vocabs['property_type']), 8)\n",
        "        self.embed_room_type = nn.Embedding(len(processor.vocabs['room_type']), 4)\n",
        "        self.text_transformer = SentenceTransformer(self.config['TEXT_MODEL_NAME'])\n",
        "        # Freeze the transformer completely for the baseline\n",
        "        for param in self.text_transformer.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # --- Calculate the total input dimension for the MLP ---\n",
        "        text_embed_dim = self.text_transformer.get_sentence_embedding_dimension()\n",
        "        total_input_dim = (\n",
        "            config['GEO_EMBEDDING_DIM'] +      # Location\n",
        "            8 + 4 + 4 +                       # Size (embeddings + 4 numerical)\n",
        "            8 +                               # Quality (8 numerical)\n",
        "            2 +                               # Seasonality\n",
        "            text_embed_dim +                  # Amenities\n",
        "            text_embed_dim                    # Description\n",
        "        )\n",
        "\n",
        "        # --- Main MLP (Smaller and with Dropout) ---\n",
        "        self.main_mlp = nn.Sequential(\n",
        "            nn.Linear(total_input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "\n",
        "            nn.Linear(128, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, batch: dict) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Performs a full forward pass, returning only the final prediction.\n",
        "        \"\"\"\n",
        "        # --- Prepare all feature tensors ---\n",
        "        loc_input = batch['loc_geo_position']\n",
        "        size_input = torch.cat([\n",
        "            self.embed_property_type(batch['size_property_type']),\n",
        "            self.embed_room_type(batch['size_room_type']),\n",
        "            batch['size_accommodates'].unsqueeze(1),\n",
        "            batch['size_bedrooms'].unsqueeze(1),\n",
        "            batch['size_beds'].unsqueeze(1),\n",
        "            batch['size_bathrooms'].unsqueeze(1)\n",
        "        ], dim=1)\n",
        "        qual_cols = [\n",
        "            \"review_scores_rating\", \"review_scores_cleanliness\", \"review_scores_checkin\",\n",
        "            \"review_scores_communication\", \"review_scores_location\", \"review_scores_value\",\n",
        "            \"total_reviews\", \"host_is_superhost\"\n",
        "        ]\n",
        "        qual_input = torch.cat([batch[f'qual_{c}'].unsqueeze(1) for c in qual_cols], dim=1)\n",
        "        season_input = batch['season_cyclical']\n",
        "\n",
        "        # Get text embeddings (on the fly)\n",
        "        amenities_tokens = {k: v.squeeze(1) for k, v in batch['amenities_tokens'].items()}\n",
        "        desc_tokens = {k: v.squeeze(1) for k, v in batch['description_tokens'].items()}\n",
        "        with torch.no_grad(): # Ensure no gradients are computed for the frozen transformer\n",
        "            amenities_embed = self.text_transformer(amenities_tokens)['sentence_embedding']\n",
        "            desc_embed = self.text_transformer(desc_tokens)['sentence_embedding']\n",
        "\n",
        "        # --- Concatenate all features into a single vector ---\n",
        "        full_input_vector = torch.cat([\n",
        "            loc_input, size_input, qual_input, season_input, amenities_embed, desc_embed\n",
        "        ], dim=1)\n",
        "\n",
        "        # --- Pass through the main MLP ---\n",
        "        return self.main_mlp(full_input_vector).squeeze(-1)\n",
        "\n",
        "    def count_parameters(self):\n",
        "        \"\"\"Counts and prints the number of trainable and frozen parameters.\"\"\"\n",
        "        total_trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "        total_frozen = sum(p.numel() for p in self.parameters() if not p.requires_grad)\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"{'Baseline V2 Model Parameter Analysis':^40}\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"{'Total Trainable Parameters:':<30} {total_trainable:,}\")\n",
        "        print(f\"{'Total Frozen Parameters:':<30} {total_frozen:,}\")\n",
        "        print(f\"{'Total Parameters:':<30} {(total_trainable + total_frozen):,}\")\n",
        "        print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "ccX-U8sKyDlR"
      },
      "id": "ccX-U8sKyDlR",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "48182785",
      "metadata": {
        "id": "48182785"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader, device):\n",
        "    \"\"\"Calculates validation loss (MSE) and Mean Absolute Percentage Error (MAPE).\"\"\"\n",
        "    model.eval()\n",
        "    total_loss, total_mape = 0.0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
        "            # Move batch to device\n",
        "            for k, v in batch.items():\n",
        "                if isinstance(v, torch.Tensor): batch[k] = v.to(device)\n",
        "                else: batch[k] = {sk: sv.to(device) for sk, sv in v.items()}\n",
        "\n",
        "            targets_price = batch['target_price']\n",
        "            targets_log_dev = batch['target_log_deviation']\n",
        "\n",
        "            # Forward pass\n",
        "            with torch.amp.autocast(device_type=device, dtype=torch.float16, enabled=(device==\"cuda\")):\n",
        "                preds_log_dev = model(batch)\n",
        "                loss = torch.mean((preds_log_dev - targets_log_dev).float().pow(2))\n",
        "                predicted_log_price = preds_log_dev + batch['neighborhood_log_mean']\n",
        "                price_preds = torch.expm1(predicted_log_price)\n",
        "                mape = (torch.abs(price_preds - targets_price) / (targets_price + 1e-6)).mean()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_mape += mape.item()\n",
        "\n",
        "    return total_loss / len(data_loader), total_mape / len(data_loader)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, scheduler, config):\n",
        "    \"\"\"Main function to train the model, with early stopping.\"\"\"\n",
        "    print(\"\\n--- Starting Baseline Model Training ---\")\n",
        "    history, best_val_mape = [], float('inf')\n",
        "    best_model_state, patience_counter = None, 0\n",
        "    scaler = torch.amp.GradScaler(enabled=(config['DEVICE'] == \"cuda\"))\n",
        "    start_time = time.time()\n",
        "\n",
        "    header = f\"{'Epoch':>5} | {'Time':>8} | {'Train RMSE':>12} | {'Val RMSE':>10} | {'Val MAPE (%)':>12} | {'Patience':>8}\"\n",
        "    print(header); print(\"-\" * len(header))\n",
        "\n",
        "    for epoch in range(config['N_EPOCHS']):\n",
        "        model.train()\n",
        "        train_loss_epoch = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['N_EPOCHS']}\", leave=False):\n",
        "            # Move batch to device\n",
        "            for k, v in batch.items():\n",
        "                if isinstance(v, torch.Tensor): batch[k] = v.to(config['DEVICE'])\n",
        "                else: batch[k] = {sk: sv.to(config['DEVICE']) for sk, sv in v.items()}\n",
        "\n",
        "            with torch.amp.autocast(device_type=config['DEVICE'], dtype=torch.float16, enabled=(config['DEVICE']==\"cuda\")):\n",
        "                preds_log_dev = model(batch)\n",
        "                loss = torch.mean((preds_log_dev - batch[\"target_log_deviation\"]).float().pow(2))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            train_loss_epoch += loss.item()\n",
        "\n",
        "        val_mse, val_mape = evaluate_model(model, val_loader, config['DEVICE'])\n",
        "        train_rmse, val_rmse = np.sqrt(train_loss_epoch / len(train_loader)), np.sqrt(val_mse)\n",
        "        elapsed_time = time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time))\n",
        "\n",
        "        if val_mape < best_val_mape - config['EARLY_STOPPING_MIN_DELTA']:\n",
        "            best_val_mape, patience_counter = val_mape, 0\n",
        "            best_model_state = model.state_dict()\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        print(f\"{epoch+1:>5} | {elapsed_time:>8} | {train_rmse:>12.4f} | {val_rmse:>10.4f} | {val_mape*100:>12.2f} | {patience_counter:>8}\")\n",
        "        history.append({'epoch': epoch, 'train_rmse': train_rmse, 'val_rmse': val_rmse, 'val_mape': val_mape})\n",
        "        scheduler.step(val_mape)\n",
        "\n",
        "        if patience_counter >= config['EARLY_STOPPING_PATIENCE']:\n",
        "            print(f\"--- Early Stopping Triggered (MAPE did not improve for {patience_counter} epochs) ---\"); break\n",
        "\n",
        "    print(\"\\n--- Training Complete ---\")\n",
        "    if best_model_state:\n",
        "        print(f\"Loading best model state with Val MAPE: {best_val_mape*100:.2f}%\")\n",
        "        model.load_state_dict(best_model_state)\n",
        "    return model, pd.DataFrame(history)\n",
        "\n",
        "def save_artifacts(model, processor, config, metrics):\n",
        "    \"\"\"Saves the trained model, feature processor, config, and metrics.\"\"\"\n",
        "    timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
        "    filename = f\"{config['CITY']}_baseline_model_artifacts_{timestamp}.pt\"\n",
        "    save_path = os.path.join(config['DRIVE_SAVE_PATH'], filename)\n",
        "    os.makedirs(config['DRIVE_SAVE_PATH'], exist_ok=True)\n",
        "\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'feature_processor': processor,\n",
        "        'config': config,\n",
        "        'final_metrics': metrics\n",
        "    }, save_path)\n",
        "\n",
        "    print(f\"\\nBaseline artifacts successfully saved to: {save_path}\")\n",
        "    return save_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# --- MAIN EXECUTION SCRIPT ---\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. Imports and Global Configuration\n",
        "from config import config\n",
        "from utils import set_seed\n",
        "from data_processing import load_and_split_data, FeatureProcessor, create_dataloaders\n",
        "\n",
        "set_seed(config['SEED'])\n",
        "print(\"--- Configuration Settings ---\")\n",
        "for key, value in config.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "print(f\"\\nUsing device: {config['DEVICE']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqrpgGQTyLPZ",
        "outputId": "2c1de85c-d40b-4ad1-9f5a-5ffce3c7fd46"
      },
      "id": "mqrpgGQTyLPZ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All random seeds set to 42.\n",
            "--- Configuration Settings ---\n",
            "CITY: toronto\n",
            "DEVICE: cuda\n",
            "DRIVE_SAVE_PATH: /content/drive/MyDrive/Colab_Notebooks/Airbnb_Project/artifacts/\n",
            "TEXT_MODEL_NAME: BAAI/bge-small-en-v1.5\n",
            "VAL_SIZE: 0.05\n",
            "SEED: 42\n",
            "BATCH_SIZE: 256\n",
            "VALIDATION_BATCH_SIZE: 512\n",
            "LEARNING_RATE: 0.001\n",
            "TRANSFORMER_LEARNING_RATE: 1e-05\n",
            "N_EPOCHS: 100\n",
            "HIDDEN_LAYERS_LOCATION: [32, 16]\n",
            "HIDDEN_LAYERS_SIZE_CAPACITY: [32, 16]\n",
            "HIDDEN_LAYERS_QUALITY: [32, 16]\n",
            "HIDDEN_LAYERS_AMENITIES: [64, 32]\n",
            "HIDDEN_LAYERS_DESCRIPTION: [64, 32]\n",
            "HIDDEN_LAYERS_SEASONALITY: [16]\n",
            "GEO_EMBEDDING_DIM: 32\n",
            "EARLY_STOPPING_PATIENCE: 10\n",
            "EARLY_STOPPING_MIN_DELTA: 0.001\n",
            "SCHEDULER_PATIENCE: 2\n",
            "SCHEDULER_FACTOR: 0.5\n",
            "\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load and Split Data\n",
        "train_df, val_df, neighborhood_log_means, _, _ = load_and_split_data(config)\n",
        "print(f\"\\nTraining DataFrame shape: {train_df.shape}\")\n",
        "print(f\"Validation DataFrame shape: {val_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_dRXAE4yQqA",
        "outputId": "a9522a87-152e-46f5-b051-e8cd3f7e3864"
      },
      "id": "a_dRXAE4yQqA",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from: ./toronto_dataset_oct_20.parquet\n",
            "Stratified split complete. Listings in Train: 7,618, Val: 401\n",
            "Total records in Train: 82,065, Val: 4,327\n",
            "\n",
            "Training DataFrame shape: (82065, 29)\n",
            "Validation DataFrame shape: (4327, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Process Features\n",
        "processor = FeatureProcessor(config)\n",
        "processor.fit(train_df)\n",
        "train_features = processor.transform(train_df, neighborhood_log_means)\n",
        "val_features = processor.transform(val_df, neighborhood_log_means)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx7odzKcyScm",
        "outputId": "f205ec47-f7b5-4da9-ad7c-8f49631ae597"
      },
      "id": "cx7odzKcyScm",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting FeatureProcessor...\n",
            "Fit complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/Airbnb_Price_Project/data_processing.py:151: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['neighborhood_log_mean'].fillna(global_mean, inplace=True)\n",
            "/content/drive/MyDrive/Airbnb_Price_Project/data_processing.py:151: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['neighborhood_log_mean'].fillna(global_mean, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Instantiate Model and DataLoaders\n",
        "baseline_model = BaselineFCNV2(processor, config)\n",
        "baseline_model.count_parameters() # Print model summary\n",
        "train_loader, val_loader = create_dataloaders(train_features, val_features, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w8RDxEJyUyE",
        "outputId": "7bbbd925-9672-4376-ebbb-7857376807ab"
      },
      "id": "0w8RDxEJyUyE",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "  Baseline V2 Model Parameter Analysis  \n",
            "----------------------------------------\n",
            "Total Trainable Parameters:    110,741\n",
            "Total Frozen Parameters:       33,360,000\n",
            "Total Parameters:              33,470,741\n",
            "----------------------------------------\n",
            "DataLoaders created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Define Optimizer and Scheduler\n",
        "# For the baseline, we use a single learning rate for all trainable parameters\n",
        "optimizer = optim.AdamW(baseline_model.parameters(), lr=config['LEARNING_RATE'], weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=config['SCHEDULER_FACTOR'],\n",
        "    patience=config['SCHEDULER_PATIENCE']\n",
        ")\n",
        "print(\"\\nOptimizer and Scheduler have been defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Kpn4FnSyaLM",
        "outputId": "b4abb22d-8fb7-424f-f9fc-74293c0c2404"
      },
      "id": "9Kpn4FnSyaLM",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimizer and Scheduler have been defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Train the Model\n",
        "trained_baseline_model, history_df = train_model(\n",
        "    model=baseline_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    config=config\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHxCWdyBycYh",
        "outputId": "fc09344d-defd-4f99-ad4c-5660be946326"
      },
      "id": "gHxCWdyBycYh",
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Baseline Model Training ---\n",
            "Epoch |     Time |   Train RMSE |   Val RMSE | Val MAPE (%) | Patience\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    1 | 00:01:17 |       0.4567 |     0.3398 |        28.26 |        0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    2 | 00:02:33 |       0.3539 |     0.3367 |        27.45 |        0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    3 | 00:03:49 |       0.3442 |     0.3306 |        27.96 |        1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    4 | 00:05:05 |       0.3365 |     0.3298 |        26.99 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    5 | 00:06:20 |       0.3310 |     0.3356 |        28.37 |        1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    6 | 00:07:36 |       0.3259 |     0.3270 |        27.09 |        2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    7 | 00:08:51 |       0.3216 |     0.3325 |        28.23 |        3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    8 | 00:10:07 |       0.3146 |     0.3229 |        26.68 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    9 | 00:11:23 |       0.3098 |     0.3260 |        26.89 |        1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   10 | 00:12:38 |       0.3061 |     0.3248 |        26.31 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   11 | 00:13:54 |       0.3022 |     0.3285 |        27.12 |        1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   12 | 00:15:10 |       0.3006 |     0.3274 |        27.86 |        2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   13 | 00:16:26 |       0.2995 |     0.3262 |        26.83 |        3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   14 | 00:17:41 |       0.2947 |     0.3262 |        26.71 |        4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   15 | 00:18:56 |       0.2922 |     0.3271 |        26.68 |        5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   16 | 00:20:12 |       0.2898 |     0.3248 |        26.47 |        6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   17 | 00:21:27 |       0.2868 |     0.3255 |        26.51 |        7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   18 | 00:22:42 |       0.2872 |     0.3248 |        26.56 |        8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   19 | 00:23:58 |       0.2857 |     0.3239 |        26.31 |        9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   20 | 00:25:13 |       0.2853 |     0.3262 |        26.56 |       10\n",
            "--- Early Stopping Triggered (MAPE did not improve for 10 epochs) ---\n",
            "\n",
            "--- Training Complete ---\n",
            "Loading best model state with Val MAPE: 26.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Final Evaluation and Metrics Reporting\n",
        "print(\"\\n--- Final Model Evaluation ---\")\n",
        "final_train_mse, final_train_mape = evaluate_model(trained_baseline_model, train_loader, config['DEVICE'])\n",
        "final_val_mse, final_val_mape = evaluate_model(trained_baseline_model, val_loader, config['DEVICE'])\n",
        "\n",
        "final_metrics = {\n",
        "    \"train_rmse\": np.sqrt(final_train_mse),\n",
        "    \"train_mape\": final_train_mape,\n",
        "    \"val_rmse\": np.sqrt(final_val_mse),\n",
        "    \"val_mape\": final_val_mape\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"{'Final Baseline Performance Metrics':^50}\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Train RMSE:      {final_metrics['train_rmse']:.4f}\")\n",
        "print(f\"Validation RMSE: {final_metrics['val_rmse']:.4f}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Train MAPE:      {final_metrics['train_mape'] * 100:.2f}%\")\n",
        "print(f\"Validation MAPE: {final_metrics['val_mape'] * 100:.2f}%\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jRaM3Bayd_Z",
        "outputId": "02a49802-9103-47ac-c095-958ffe755101"
      },
      "id": "9jRaM3Bayd_Z",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Model Evaluation ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "        Final Baseline Performance Metrics        \n",
            "==================================================\n",
            "Train RMSE:      0.2267\n",
            "Validation RMSE: 0.3262\n",
            "--------------------------------------------------\n",
            "Train MAPE:      18.08%\n",
            "Validation MAPE: 26.56%\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Save Model Artifacts\n",
        "save_artifacts(trained_baseline_model, processor, config, final_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "xx70lrRYynfL",
        "outputId": "c6073f3d-022b-4b14-fe63-21a954d4dd89"
      },
      "id": "xx70lrRYynfL",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Baseline artifacts successfully saved to: /content/drive/MyDrive/Colab_Notebooks/Airbnb_Project/artifacts/toronto_baseline_model_artifacts_20251104_125516.pt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab_Notebooks/Airbnb_Project/artifacts/toronto_baseline_model_artifacts_20251104_125516.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The following functions (train_model, evaluate_model) are assumed to be\n",
        "# defined in your notebook's environment from the previous run. If not, you\n",
        "# can uncomment them from the baseline script I provided earlier.\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. FLEXIBLE MODEL DEFINITION FOR ABLATION\n",
        "# ==============================================================================\n",
        "\n",
        "class AblationFCN(nn.Module):\n",
        "    \"\"\"\n",
        "    A flexible, fully-connected network for ablation studies.\n",
        "\n",
        "    This model can dynamically exclude one or more feature axes (e.g.,\n",
        "    'description', 'quality') to measure their impact on performance. The\n",
        "    input layer size and the forward pass are adjusted automatically based\n",
        "    on the `exclude_axes` list provided during initialization.\n",
        "    \"\"\"\n",
        "    def __init__(self, processor: 'FeatureProcessor', config: dict,\n",
        "                 dropout_rate: float = 0.4, exclude_axes: list = None):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.device = self.config['DEVICE']\n",
        "        self.exclude_axes = set(exclude_axes) if exclude_axes else set()\n",
        "\n",
        "        print(f\"Initializing AblationFCN, excluding: {self.exclude_axes}\")\n",
        "\n",
        "        # --- Embeddings & Encoders (defined for all potential axes) ---\n",
        "        self.embed_property_type = nn.Embedding(len(processor.vocabs['property_type']), 8)\n",
        "        self.embed_room_type = nn.Embedding(len(processor.vocabs['room_type']), 4)\n",
        "        self.text_transformer = SentenceTransformer(self.config['TEXT_MODEL_NAME'])\n",
        "        for param in self.text_transformer.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # --- Dynamically calculate the total input dimension ---\n",
        "        text_embed_dim = self.text_transformer.get_sentence_embedding_dimension()\n",
        "        axis_dims = {\n",
        "            'location': config['GEO_EMBEDDING_DIM'],\n",
        "            'size': 8 + 4 + 4,  # prop_embed + room_embed + 4 numerical\n",
        "            'quality': 8,      # 8 numerical quality features\n",
        "            'seasonality': 2,\n",
        "            'amenities': text_embed_dim,\n",
        "            'description': text_embed_dim\n",
        "        }\n",
        "\n",
        "        total_input_dim = 0\n",
        "        for axis, dim in axis_dims.items():\n",
        "            if axis not in self.exclude_axes:\n",
        "                total_input_dim += dim\n",
        "\n",
        "        print(f\"Total input dimension for MLP: {total_input_dim}\")\n",
        "\n",
        "        # --- Main MLP (architecture remains the same) ---\n",
        "        self.main_mlp = nn.Sequential(\n",
        "            nn.Linear(total_input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(128, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, batch: dict) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass that dynamically constructs the input vector.\n",
        "        \"\"\"\n",
        "        tensors_to_concat = []\n",
        "\n",
        "        # --- Conditionally prepare and append feature tensors ---\n",
        "        if 'location' not in self.exclude_axes:\n",
        "            tensors_to_concat.append(batch['loc_geo_position'])\n",
        "\n",
        "        if 'size' not in self.exclude_axes:\n",
        "            size_input = torch.cat([\n",
        "                self.embed_property_type(batch['size_property_type']),\n",
        "                self.embed_room_type(batch['size_room_type']),\n",
        "                batch['size_accommodates'].unsqueeze(1),\n",
        "                batch['size_bedrooms'].unsqueeze(1),\n",
        "                batch['size_beds'].unsqueeze(1),\n",
        "                batch['size_bathrooms'].unsqueeze(1)\n",
        "            ], dim=1)\n",
        "            tensors_to_concat.append(size_input)\n",
        "\n",
        "        if 'quality' not in self.exclude_axes:\n",
        "            qual_cols = [\n",
        "                \"review_scores_rating\", \"review_scores_cleanliness\", \"review_scores_checkin\",\n",
        "                \"review_scores_communication\", \"review_scores_location\", \"review_scores_value\",\n",
        "                \"total_reviews\", \"host_is_superhost\"\n",
        "            ]\n",
        "            qual_input = torch.cat([batch[f'qual_{c}'].unsqueeze(1) for c in qual_cols], dim=1)\n",
        "            tensors_to_concat.append(qual_input)\n",
        "\n",
        "        if 'seasonality' not in self.exclude_axes:\n",
        "            tensors_to_concat.append(batch['season_cyclical'])\n",
        "\n",
        "        # Text embeddings are handled carefully to avoid unnecessary computation\n",
        "        with torch.no_grad():\n",
        "            if 'amenities' not in self.exclude_axes:\n",
        "                amenities_tokens = {k: v.squeeze(1) for k, v in batch['amenities_tokens'].items()}\n",
        "                amenities_embed = self.text_transformer(amenities_tokens)['sentence_embedding']\n",
        "                tensors_to_concat.append(amenities_embed)\n",
        "\n",
        "            if 'description' not in self.exclude_axes:\n",
        "                desc_tokens = {k: v.squeeze(1) for k, v in batch['description_tokens'].items()}\n",
        "                desc_embed = self.text_transformer(desc_tokens)['sentence_embedding']\n",
        "                tensors_to_concat.append(desc_embed)\n",
        "\n",
        "        # --- Concatenate all selected features and pass through MLP ---\n",
        "        full_input_vector = torch.cat(tensors_to_concat, dim=1)\n",
        "        return self.main_mlp(full_input_vector).squeeze(-1)\n",
        "\n",
        "    def count_parameters(self):\n",
        "        total_trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "        total_frozen = sum(p.numel() for p in self.parameters() if not p.requires_grad)\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Ablation Model Parameter Analysis (Excluding: {self.exclude_axes})\")\n",
        "        print(f\"{'Total Trainable Parameters:':<30} {total_trainable:,}\")\n",
        "        print(f\"{'Total Frozen Parameters:':<30} {total_frozen:,}\")\n",
        "        print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "KbyJJiVt8Uk4"
      },
      "id": "KbyJJiVt8Uk4",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. WRAPPER FUNCTION TO RUN AN EXPERIMENT\n",
        "# ==============================================================================\n",
        "\n",
        "def run_ablation_experiment(\n",
        "    exclude_axes: list,\n",
        "    config: dict,\n",
        "    processor: 'FeatureProcessor',\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader\n",
        "):\n",
        "    \"\"\"\n",
        "    Initializes, trains, and evaluates an AblationFCN model, tracking full metrics.\n",
        "\n",
        "    Args:\n",
        "        exclude_axes (list): A list of strings naming the axes to remove.\n",
        "        config (dict): The global configuration dictionary.\n",
        "        processor (FeatureProcessor): The fitted feature processor.\n",
        "        train_loader (DataLoader): The training data loader.\n",
        "        val_loader (DataLoader): The validation data loader.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the final performance metrics (RMSE and MAPE\n",
        "              for both train and validation sets) for this run.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"  STARTING ABLATION EXPERIMENT: EXCLUDING {exclude_axes}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # 1. Instantiate the model with the specified exclusions\n",
        "    model = AblationFCN(processor, config, exclude_axes=exclude_axes)\n",
        "    model.count_parameters()\n",
        "\n",
        "    # 2. Define a new optimizer and scheduler for this specific model\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config['LEARNING_RATE'], weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=config['SCHEDULER_FACTOR'],\n",
        "        patience=config['SCHEDULER_PATIENCE']\n",
        "    )\n",
        "\n",
        "    # 3. Train the model using the existing training function\n",
        "    trained_model, _ = train_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    # 4. Perform final evaluation on both training and validation sets\n",
        "    print(\"\\n--- Final Evaluation for this Ablation Run ---\")\n",
        "    # Note: Use tqdm's `disable` parameter if you don't want the progress bar here\n",
        "    final_train_mse, final_train_mape = evaluate_model(trained_model, train_loader, config['DEVICE'])\n",
        "    final_val_mse, final_val_mape = evaluate_model(trained_model, val_loader, config['DEVICE'])\n",
        "\n",
        "    metrics = {\n",
        "        \"excluded_axes\": str(exclude_axes), # Use string for better DataFrame display\n",
        "        \"train_rmse\": np.sqrt(final_train_mse),\n",
        "        \"val_rmse\": np.sqrt(final_val_mse),\n",
        "        \"train_mape\": final_train_mape,\n",
        "        \"val_mape\": final_val_mape\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"*\"*70)\n",
        "    print(f\"  ABLATION RUN COMPLETE: EXCLUDING {exclude_axes}\")\n",
        "    print(f\"  Final Train RMSE:      {metrics['train_rmse']:.4f}\")\n",
        "    print(f\"  Final Validation RMSE: {metrics['val_rmse']:.4f}\")\n",
        "    print(f\"  Final Train MAPE:      {metrics['train_mape'] * 100:.3f}%\")\n",
        "    print(f\"  Final Validation MAPE: {metrics['val_mape'] * 100:.3f}%\")\n",
        "    print(\"*\"*70 + \"\\n\")\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "NMv1w7eU8poT"
      },
      "id": "NMv1w7eU8poT",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. EXAMPLE USAGE (RUN THIS IN YOUR NOTEBOOK)\n",
        "# ==============================================================================\n",
        "\n",
        "# This assumes you have the following objects loaded in your notebook:\n",
        "# - config: The configuration dictionary\n",
        "# - processor: The FITTED FeatureProcessor instance\n",
        "# - train_loader, val_loader: The DataLoaders\n",
        "# - final_metrics: The dictionary of metrics from your initial baseline run.\n",
        "#   If you don't have it, you can create it manually like this:\n",
        "#   final_metrics = {'train_rmse': 0.25, 'val_rmse': 0.30, 'train_mape': 0.15, 'val_mape': 0.18}\n",
        "\n",
        "# Store results from all experiments\n",
        "ablation_results = []\n",
        "\n",
        "# IMPORTANT: Add the original baseline's results for direct comparison.\n",
        "# This makes your final summary table much more informative.\n",
        "baseline_performance = final_metrics.copy() # Use the metrics from your first V2 run\n",
        "baseline_performance['excluded_axes'] = \"['None (Baseline)']\"\n",
        "ablation_results.append(baseline_performance)"
      ],
      "metadata": {
        "id": "Do3sZRBo9YTy"
      },
      "id": "Do3sZRBo9YTy",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Experiment 1: Remove 'description' axis ---\n",
        "exp1_metrics = run_ablation_experiment(\n",
        "    exclude_axes=['description'],\n",
        "    config=config,\n",
        "    processor=processor,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader\n",
        ")\n",
        "ablation_results.append(exp1_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wWTdcvx9Zu7",
        "outputId": "4f1e3195-6f50-49d5-db93-3a109a9356e2"
      },
      "id": "-wWTdcvx9Zu7",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  STARTING ABLATION EXPERIMENT: EXCLUDING ['description']\n",
            "======================================================================\n",
            "Initializing AblationFCN, excluding: {'description'}\n",
            "Total input dimension for MLP: 442\n",
            "--------------------------------------------------\n",
            "Ablation Model Parameter Analysis (Excluding: {'description'})\n",
            "Total Trainable Parameters:    61,589\n",
            "Total Frozen Parameters:       33,360,000\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Starting Baseline Model Training ---\n",
            "Epoch |     Time |   Train RMSE |   Val RMSE | Val MAPE (%) | Patience\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    1 | 00:01:15 |       0.4425 |     0.3520 |        29.78 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    2 | 00:02:31 |       0.3625 |     0.3475 |        28.95 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    3 | 00:03:47 |       0.3514 |     0.3395 |        28.03 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    4 | 00:05:03 |       0.3455 |     0.3386 |        28.04 |        1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    5 | 00:06:20 |       0.3410 |     0.3395 |        28.62 |        2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    6 | 00:07:35 |       0.3385 |     0.3452 |        28.75 |        3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    7 | 00:08:51 |       0.3321 |     0.3384 |        27.98 |        4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    8 | 00:10:07 |       0.3292 |     0.3425 |        29.02 |        5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    9 | 00:11:23 |       0.3274 |     0.3395 |        27.23 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   10 | 00:12:39 |       0.3261 |     0.3370 |        28.33 |        1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   11 | 00:13:54 |       0.3224 |     0.3470 |        28.85 |        2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   12 | 00:15:09 |       0.3212 |     0.3415 |        28.12 |        3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   13 | 00:16:23 |       0.3178 |     0.3397 |        28.25 |        4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   14 | 00:17:37 |       0.3161 |     0.3387 |        27.83 |        5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   15 | 00:18:52 |       0.3146 |     0.3406 |        28.33 |        6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   16 | 00:20:06 |       0.3117 |     0.3394 |        27.66 |        7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   17 | 00:21:21 |       0.3120 |     0.3413 |        27.98 |        8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   18 | 00:22:36 |       0.3112 |     0.3403 |        28.01 |        9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   19 | 00:23:50 |       0.3091 |     0.3384 |        27.90 |       10\n",
            "--- Early Stopping Triggered (MAPE did not improve for 10 epochs) ---\n",
            "\n",
            "--- Training Complete ---\n",
            "Loading best model state with Val MAPE: 27.23%\n",
            "\n",
            "--- Final Evaluation for this Ablation Run ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**********************************************************************\n",
            "  ABLATION RUN COMPLETE: EXCLUDING ['description']\n",
            "  Final Train RMSE:      0.2687\n",
            "  Final Validation RMSE: 0.3384\n",
            "  Final Train MAPE:      22.114%\n",
            "  Final Validation MAPE: 27.901%\n",
            "**********************************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Experiment 2: Remove 'amenities' axis ---\n",
        "exp2_metrics = run_ablation_experiment(\n",
        "    exclude_axes=['amenities'],\n",
        "    config=config,\n",
        "    processor=processor,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader\n",
        ")\n",
        "ablation_results.append(exp2_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdTb_aJB9chE",
        "outputId": "ddc6b11f-cfaa-4844-a4e8-24688a3e369a"
      },
      "id": "PdTb_aJB9chE",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  STARTING ABLATION EXPERIMENT: EXCLUDING ['amenities']\n",
            "======================================================================\n",
            "Initializing AblationFCN, excluding: {'amenities'}\n",
            "Total input dimension for MLP: 442\n",
            "--------------------------------------------------\n",
            "Ablation Model Parameter Analysis (Excluding: {'amenities'})\n",
            "Total Trainable Parameters:    61,589\n",
            "Total Frozen Parameters:       33,360,000\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Starting Baseline Model Training ---\n",
            "Epoch |     Time |   Train RMSE |   Val RMSE | Val MAPE (%) | Patience\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    1 | 00:01:14 |       0.4471 |     0.3516 |        29.88 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    2 | 00:02:29 |       0.3598 |     0.3348 |        27.33 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    3 | 00:03:44 |       0.3490 |     0.3368 |        27.60 |        1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    4 | 00:04:59 |       0.3412 |     0.3288 |        26.77 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    5 | 00:06:14 |       0.3343 |     0.3346 |        27.16 |        1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    6 | 00:07:29 |       0.3293 |     0.3351 |        26.69 |        2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    7 | 00:08:44 |       0.3274 |     0.3302 |        27.19 |        3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    8 | 00:09:59 |       0.3240 |     0.3386 |        27.55 |        4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    9 | 00:11:14 |       0.3214 |     0.3364 |        27.10 |        5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   10 | 00:12:30 |       0.3126 |     0.3355 |        27.86 |        6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   11 | 00:13:45 |       0.3103 |     0.3407 |        27.17 |        7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   12 | 00:15:00 |       0.3075 |     0.3405 |        27.32 |        8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   13 | 00:16:15 |       0.3029 |     0.3412 |        27.94 |        9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   14 | 00:17:30 |       0.3014 |     0.3379 |        27.51 |       10\n",
            "--- Early Stopping Triggered (MAPE did not improve for 10 epochs) ---\n",
            "\n",
            "--- Training Complete ---\n",
            "Loading best model state with Val MAPE: 26.77%\n",
            "\n",
            "--- Final Evaluation for this Ablation Run ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**********************************************************************\n",
            "  ABLATION RUN COMPLETE: EXCLUDING ['amenities']\n",
            "  Final Train RMSE:      0.2539\n",
            "  Final Validation RMSE: 0.3379\n",
            "  Final Train MAPE:      20.701%\n",
            "  Final Validation MAPE: 27.515%\n",
            "**********************************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Experiment 3: Remove both 'description' and 'amenities' ---\n",
        "exp3_metrics = run_ablation_experiment(\n",
        "    exclude_axes=['description', 'amenities'],\n",
        "    config=config,\n",
        "    processor=processor,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader\n",
        ")\n",
        "ablation_results.append(exp3_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O-u5zlh9epP",
        "outputId": "97e49b1c-afcf-43a3-966f-6d7ecd8ade89"
      },
      "id": "-O-u5zlh9epP",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  STARTING ABLATION EXPERIMENT: EXCLUDING ['description', 'amenities']\n",
            "======================================================================\n",
            "Initializing AblationFCN, excluding: {'amenities', 'description'}\n",
            "Total input dimension for MLP: 58\n",
            "--------------------------------------------------\n",
            "Ablation Model Parameter Analysis (Excluding: {'amenities', 'description'})\n",
            "Total Trainable Parameters:    12,437\n",
            "Total Frozen Parameters:       33,360,000\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Starting Baseline Model Training ---\n",
            "Epoch |     Time |   Train RMSE |   Val RMSE | Val MAPE (%) | Patience\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    1 | 00:01:14 |       0.4639 |     0.3675 |        31.28 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    2 | 00:02:29 |       0.3748 |     0.3606 |        29.82 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    3 | 00:03:44 |       0.3647 |     0.3543 |        29.08 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    4 | 00:04:59 |       0.3586 |     0.3472 |        28.75 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    5 | 00:06:13 |       0.3543 |     0.3461 |        28.54 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    6 | 00:07:28 |       0.3508 |     0.3441 |        27.79 |        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    7 | 00:08:44 |       0.3483 |     0.3465 |        28.85 |        1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    8 | 00:09:58 |       0.3454 |     0.3425 |        28.00 |        2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    9 | 00:11:14 |       0.3435 |     0.3470 |        28.06 |        3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   10 | 00:12:30 |       0.3408 |     0.3456 |        27.96 |        4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   11 | 00:13:46 |       0.3393 |     0.3418 |        27.71 |        5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   12 | 00:15:02 |       0.3381 |     0.3451 |        28.35 |        6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   13 | 00:16:17 |       0.3360 |     0.3422 |        28.45 |        7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   14 | 00:17:33 |       0.3364 |     0.3425 |        28.35 |        8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   15 | 00:18:49 |       0.3340 |     0.3453 |        28.33 |        9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   16 | 00:20:05 |       0.3333 |     0.3449 |        28.33 |       10\n",
            "--- Early Stopping Triggered (MAPE did not improve for 10 epochs) ---\n",
            "\n",
            "--- Training Complete ---\n",
            "Loading best model state with Val MAPE: 27.79%\n",
            "\n",
            "--- Final Evaluation for this Ablation Run ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                         "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**********************************************************************\n",
            "  ABLATION RUN COMPLETE: EXCLUDING ['description', 'amenities']\n",
            "  Final Train RMSE:      0.3091\n",
            "  Final Validation RMSE: 0.3449\n",
            "  Final Train MAPE:      25.623%\n",
            "  Final Validation MAPE: 28.328%\n",
            "**********************************************************************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# FINAL SUMMARY AND SAVING OF ABLATION STUDY RESULTS\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"--- Finalizing Ablation Study ---\")\n",
        "\n",
        "# --- 1. Create and Display Summary Table ---\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(f\"{'ABLATION STUDY SUMMARY':^80}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(ablation_results)\n",
        "\n",
        "# Format MAPE columns for percentage display\n",
        "results_df['train_mape_pct'] = results_df['train_mape'] * 100\n",
        "results_df['val_mape_pct'] = results_df['val_mape'] * 100\n",
        "\n",
        "# Define columns to display and their order\n",
        "display_cols = ['excluded_axes', 'train_rmse', 'val_rmse', 'train_mape_pct', 'val_mape_pct']\n",
        "\n",
        "# Print the final formatted table to the console\n",
        "print(results_df[display_cols].to_string(index=False, float_format=\"%.4f\"))\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "# --- 2. Save the Results DataFrame to a CSV file ---\n",
        "# Create a timestamp for the filename\n",
        "timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
        "filename = f\"{config['CITY']}_ablation_results_{timestamp}.csv\"\n",
        "\n",
        "# Construct the full save path using the path from your config\n",
        "save_path = os.path.join(config['DRIVE_SAVE_PATH'], filename)\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(config['DRIVE_SAVE_PATH'], exist_ok=True)\n",
        "\n",
        "# Save the DataFrame (including all columns, not just the display ones)\n",
        "results_df.to_csv(save_path, index=False, float_format=\"%.6f\")\n",
        "\n",
        "print(f\"\\nAblation study results successfully saved to:\")\n",
        "print(save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrYPowrY8ldX",
        "outputId": "a0e56304-b7a6-4bda-dd86-256ab160401a"
      },
      "id": "HrYPowrY8ldX",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Finalizing Ablation Study ---\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                             ABLATION STUDY SUMMARY                             \n",
            "================================================================================\n",
            "               excluded_axes  train_rmse  val_rmse  train_mape_pct  val_mape_pct\n",
            "         ['None (Baseline)']      0.2267    0.3262         18.0824       26.5570\n",
            "             ['description']      0.2687    0.3384         22.1143       27.9011\n",
            "               ['amenities']      0.2539    0.3379         20.7007       27.5146\n",
            "['description', 'amenities']      0.3091    0.3449         25.6233       28.3275\n",
            "================================================================================\n",
            "\n",
            "Ablation study results successfully saved to:\n",
            "/content/drive/MyDrive/Colab_Notebooks/Airbnb_Project/artifacts/toronto_ablation_results_20251104_140805.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zVSggMwEMkFT"
      },
      "id": "zVSggMwEMkFT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}